from . import autodecode as autodecode
from .checks import checktype as checktype
from typing import Any, Optional

class TorchTensor: ...

def reraise_exception(exn: Any) -> None: ...
def identity(x: Any): ...
def compose2(f: Any, g: Any): ...
def compose(*args: Any): ...
def pipeline(source: Any, *args: Any): ...
def getfirst(a: Any, keys: Any, default: Optional[Any] = ..., missing_is_error: bool = ...): ...
def parse_field_spec(fields: Any): ...
def transform_with(sample: Any, transformers: Any): ...
def transformer(transformers: Any): ...
def info(data: Any, fmt: Optional[Any] = ..., n: int = ..., every: int = ..., width: int = ..., stream: Any = ..., name: str = ...) -> None: ...
def shuffle(data: Any, bufsize: int = ..., initial: int = ..., rng: Any = ..., handler: Optional[Any] = ...) -> None: ...
def select(data: Any, predicate: Any) -> None: ...
def decode(data: Any, *args: Any, handler: Any = ..., **kw: Any) -> None: ...
def map(data: Any, f: Any, handler: Any = ...) -> None: ...
def rename(data: Any, handler: Any = ..., **kw: Any) -> None: ...
def associate(data: Any, associator: Any, **kw: Any) -> None: ...
def map_dict(data: Any, handler: Any = ..., **kw: Any) -> None: ...
def to_tuple(data: Any, *args: Any, handler: Any = ...) -> None: ...
def map_tuple(data: Any, *args: Any, handler: Any = ...) -> None: ...
def default_collation_fn(samples: Any, combine_tensors: bool = ..., combine_scalars: bool = ...): ...
def batched(data: Any, batchsize: int = ..., collation_fn: Any = ..., partial: bool = ...) -> None: ...
def unbatched(data: Any) -> None: ...
