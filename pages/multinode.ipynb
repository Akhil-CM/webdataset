{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "import webdataset as wds\n",
    "import braceexpand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Shards across Nodes and Workers\n",
    "\n",
    "Unlike traditional PyTorch `Dataset` instances, `WebDataset` splits data across nodes at the shard level, not at the sample level.\n",
    "\n",
    "This functionality is handled inside the `ShardList` class. Recall that `dataset = webdataset.Webdataset(urls)` is just a shorthand for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = list(braceexpand.braceexpand(\"dataset-{000000..000999}.tar\"))\n",
    "dataset = wds.ShardList(urls, splitter=wds.split_by_worker, nodesplitter=wds.split_by_node, shuffle=False)\n",
    "dataset = wds.Processor(dataset, wds.url_opener)\n",
    "dataset = wds.Processor(dataset, wds.tar_file_expander)\n",
    "dataset = wds.Processor(dataset, wds.group_by_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `nodesplitter` and `splitter` are functions that are called inside `ShardList` to split up the URLs in `urls` by node and worker. You can use any functions you like there, all they need to do is take a list of URLs and return a subset of those URLs as a result.\n",
    "\n",
    "The default `split_by_worker` looks roughly like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_split_by_worker(urls):\n",
    "    wi = torch.utils.data.get_worker_info()\n",
    "    if wi is None:\n",
    "        return urls\n",
    "    else:\n",
    "        return urls[wi.id::wi.num_workers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same approach works for multiple worker nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_split_by_node(urls):\n",
    "    node_id, node_count = torch.distributed.get_rank(), torch.distributed.get_world_size()\n",
    "    return urls[node_id::node_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = wds.WebDataset(urls, splitter=my_split_by_worker, nodesplitter=my_split_by_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can also create more complex splitting strategies if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistributedDataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistributedDataParallel training requires that each participating node receive exactly the same number of training batches as all others. The `ddp_equalize` method ensures this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = \"./shards/imagenet-train-{000000..001281}.tar\"\n",
    "dataset_size, batch_size = 1282000, 64\n",
    "dataset = wds.WebDataset(urls).decode(\"pil\").shuffle(5000).batched(batch_size, partial=False)\n",
    "loader = wds.WebLoader(dataset, num_workers=4)\n",
    "loader = loader.ddp_equalize(dataset_size // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to give the total number of batches in your dataset to `ddp_equalize`; it will compute the batches per node from this and equalize batches accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to apply `ddp_equalize` to the `WebLoader` rather than the `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
