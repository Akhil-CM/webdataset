{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a WebDataset\n",
    "\n",
    "## Using `tar`\n",
    "\n",
    "Since WebDatasets are just regular tar files, you can usually create them by just using the `tar` command. All you have to do is to arrange for any files that should be in the same sample to share the same basename. Many datasets already come that way. For those, you can simply create a WebDataset with\n",
    "\n",
    "```\n",
    "$ tar --sort=name -cf dataset.tar dataset/\n",
    "```\n",
    "\n",
    "If your dataset has some other directory layout, you may need a different file name in the archive from the name on disk. You can use the `--transform` argument to GNU tar to transform file names. You can also use the `-T` argument to read the files from a text file and embed other options in that text file.\n",
    "\n",
    "## The `tarp create` Command\n",
    "\n",
    "The [`tarp`](https://github.com/tmbdev/tarp) command is a little utility for manipulating `tar` archives. Its `create` subcommand makes it particularly simple to construct tar archives from files. The `tarp create` command takes a recipe for building\n",
    "a tar archive that contains lines of the form:\n",
    "\n",
    "```\n",
    "archive-name-1 source-name-1\n",
    "archive-name-2 source-name-2\n",
    "...\n",
    "```\n",
    "\n",
    "The source name can either be a file, \"text:something\", or \"pipe:something\".\n",
    "\n",
    "## Programmatically in Python\n",
    "\n",
    "You can also create a WebDataset with library functions in this library:\n",
    "\n",
    "- `webdataset.TarWriter` takes dictionaries containing key value pairs and writes them to disk\n",
    "- `webdataset.ShardWriter` takes dictionaries containing key value pairs and writes them to disk as a series of shards\n",
    "\n",
    "Here is a quick way of converting an existing dataset into a WebDataset; this will store all tensors as Python pickles:\n",
    "\n",
    "```Python\n",
    "sink = wds.TarWriter(\"dest.tar\")\n",
    "dataset = open_my_dataset()\n",
    "for index, (input, output) in dataset:\n",
    "    sink.write({\n",
    "        \"__key__\": \"sample%06d\" % index,\n",
    "        \"input.pyd\": input,\n",
    "        \"output.pyd\": output,\n",
    "    })\n",
    "sink.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing data as Python pickles allows most common Python datatypes to be stored, it is lossless, and the format is fast to decode.\n",
    "However, it is uncompressed and cannot be read by non-Python programs. It's often better to choose other storage formats, e.g.,\n",
    "taking advantage of common image compression formats.\n",
    "\n",
    "If you know that the input is an image and the output is an integer class, you can also write something like this:\n",
    "\n",
    "```Python\n",
    "sink = wds.TarWriter(\"dest.tar\")\n",
    "dataset = open_my_dataset()\n",
    "for index, (input, output) in dataset:\n",
    "    assert input.ndim == 3 and input.shape[2] == 3\n",
    "    assert input.dtype = np.float32 and np.amin(input) >= 0 and np.amax(input) <= 1\n",
    "    assert type(output) == int\n",
    "    sink.write({\n",
    "        \"__key__\": \"sample%06d\" % index,\n",
    "        \"input.jpg\": input,\n",
    "        \"output.cls\": output,\n",
    "    })\n",
    "sink.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `assert` statements in that loop are not necessary, but they document and illustrate the expectations for this\n",
    "particular dataset. Generally, the \".jpg\" encoder can actually encode a wide variety of array types as images. The\n",
    "\".cls\" encoder always requires an integer for encoding.\n",
    "\n",
    "Here is how you can use `TarWriter` for writing a dataset without using an encoder:\n",
    "\n",
    "```Python\n",
    "sink = wds.TarWriter(\"dest.tar\", encoder=False)\n",
    "for basename in basenames:\n",
    "    with open(f\"{basename}.png\", \"rb\") as stream):\n",
    "        image = stream.read()\n",
    "    cls = lookup_cls(basename)\n",
    "    sample = {\n",
    "        \"__key__\": basename,\n",
    "        \"input.png\": image,\n",
    "        \"target.cls\": cls\n",
    "    }\n",
    "    sink.write(sample)\n",
    "sink.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since no encoder is used, if you want to be able to read this data with the default decoder, `image` must contain a byte string corresponding to a PNG image (as indicated by the \".png\" extension on its dictionary key), and `cls` must contain an integer encoded in ASCII (as indicated by the \".cls\" extension on its dictionary key)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
