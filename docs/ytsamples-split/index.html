<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Getting Started - webdataset</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../css/theme.css" />
  <link rel="stylesheet" href="../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Getting Started";
    var mkdocs_page_input_path = "ytsamples-split.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> webdataset</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="" href="../api/index.html">API</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Examples</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../gettingstarted/">Getting Started</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../creating/">Creating Webdatasets</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../decoding/">Decoding</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../desktop/">Desktop Usage</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../howitworks/">How It Works</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../multinode/">Multinode</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../sharding/">Sharding</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../sources/">Sources</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../writing/">Writing</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../video-loading-example/">Video Loading</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Dataset Conversions</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../convert-falling-things/">Falling Things</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../convert-objectron/">Objectron</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">webdataset</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Getting Started</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="http://github.com/webdataset/webdataset/edit/master/docs/ytsamples-split.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h1 id="getting-started">Getting Started</h1>
<p>This worksheet shows how you can preprocess and split videos for deep learning. In these examples, we use Google Cloud Storage. In order to actually run this worksheet, you need:</p>
<ul>
<li><a href="https://cloud.google.com/storage/docs/gsutil_install">Install Google's <code>gsutil</code> program</a></li>
<li><a href="https://github.com/tmbdev/tarp">Install the <code>tarp</code> utility</a></li>
</ul>
<p>But it's not necessary to run the worksheet; you can follow it and apply the principles to whatever cloud, object, or local storage you use.</p>
<h1 id="sharded-youtube-files">Sharded YouTube Files</h1>
<p>We have about 6M videos downloaded from YouTube (part of the YouTube 8m dataset released by Google).</p>
<p>These videos are stored as 3000 shards, each containing about 2000 videos and each about 56 Gbytes large.</p>
<p>There is just one sample shard stored in the public bucket <code>gs://nvdata-ytsamples</code>.</p>
<pre><code class="language-python">!gsutil ls gs://nvdata-ytsamples/yt8m-lo-*.tar | head
</code></pre>
<pre><code>gs://nvdata-ytsamples/yt8m-lo-000000.tar
</code></pre>
<p>Each shard contains the video itself (<code>.mp4</code>) plus a lot of associated metadata.</p>
<pre><code class="language-python">!gsutil cat gs://nvdata-ytsamples/yt8m-lo-000000.tar | tar tf - | head
</code></pre>
<pre><code>---2pGwkL7M.annotations.xml
---2pGwkL7M.description
---2pGwkL7M.dllog
---2pGwkL7M.info.json
---2pGwkL7M.mp4
---2pGwkL7M.txt
-2cScG5TqjQ.annotations.xml
-2cScG5TqjQ.description
-2cScG5TqjQ.dllog
-2cScG5TqjQ.info.json
</code></pre>
<h1 id="splitting-the-videos">Splitting the Videos</h1>
<p>For training, we usually don't want to use the entire YouTube video at once; they are variable length and are hard to fit into the GPU. Instead, we want to split up the video into frames or short clips.</p>
<p>Here, we are using a script based on ffmpeg to split up each video into a set of clips. We also rescale all the images to a common size. The input video for this script is assumed to be <code>sample.mp4</code>, and the output clips will be stored in files like <code>sample-000000.mp4</code>.</p>
<pre><code class="language-python">%%writefile extract-segments.sh
#!/bin/bash
exec &gt; $(dirname $0)/_extract-segments-last.log 1&gt;&amp;2
#ps auxw --sort -vsz | sed 5q

set -e
set -x
set -a

size=${size:-256:128}
duration=${duration:-2}
count=${count:-999999999} 

# get mp4 metadata (total length, etc.)
ffprobe sample.mp4 -v quiet -print_format json -show_format -show_streams &gt; sample.mp4.json

# perform the rescaling and splitting
ffmpeg -loglevel error -stats -i sample.mp4 \
    -vf &quot;scale=$size:force_original_aspect_ratio=decrease,pad=$size:(ow-iw)/2:(oh-ih)/2&quot; \
    -c:a copy -f segment -segment_time $duration -reset_timestamps 1  \
    -segment_format_options movflags=+faststart \
    sample-%06d.mp4

# copy the metadata into each video fragment
for s in sample-??????.mp4; do
    b=$(basename $s .mp4)
    cp sample.mp4.json $b.mp4.json || true
    cp sample.info.json $b.info.json || true
done
</code></pre>
<pre><code>Writing extract-segments.sh
</code></pre>
<pre><code class="language-python">!chmod 755 ./extract-segments.sh
</code></pre>
<h1 id="running-the-script-over-all-videos-in-a-shard">Running the Script over All Videos in a Shard</h1>
<p>Next, we use the <code>tarp</code> command to iterate the above script over each <code>.mp4</code> file in shard <code>000000</code>.</p>
<pre><code class="language-python">!tarp proc --help
</code></pre>
<pre><code>Usage:
  tarp [OPTIONS] proc [proc-OPTIONS] [Inputs...]

Application Options:
  -v                      verbose output

Help Options:
  -h, --help              Show this help message

[proc command options]
      -f, --field=        fields to extract; name or name=old1,old2,old3
      -o, --outputs=      output file
          --slice=        slice of input stream
      -c, --command=      shell command running in each sample dir
      -m, --multicommand= shell command running in each sample dir
          --shell=        shell command running in each sample dir (default:
                          /bin/bash)
</code></pre>
<pre><code class="language-python">%%writefile splitit.sh
gsutil cat gs://lpr-yt8m-lo-sharded/yt8m-lo-000000.tar |
tarp proc -m $(pwd)/extract-segments.sh - -o - |
tarp split - -o yt8m-clips-%06d.tar
</code></pre>
<pre><code>Writing splitit.sh
</code></pre>
<p>We can now run this script using:</p>
<pre><code class="language-Bash">$ bash ./splitit.sh
</code></pre>
<p>It's best to do this outside Jupyter since Jupyter doesn't work with long running shell jobs.</p>
<p>Of course, if you want to run this code over all 3000 shards, you probably will want to submit jobs based on <code>splitit.sh</code> to some job queuing system.</p>
<p>Also note that the <code>--post</code> option to <code>tarp split</code> lets us upload output shards as soon as they have been created, allowing the script to work with very little local storage.</p>
<h1 id="output">Output</h1>
<p>Let's have a look at the output to make sure it's OK.</p>
<pre><code class="language-python">!tar tf yt8m-clips-000000.tar | head
</code></pre>
<pre><code>---2pGwkL7M/000000.mp4.json
---2pGwkL7M/000000.info.json
---2pGwkL7M/000000.mp4
---2pGwkL7M/000001.info.json
---2pGwkL7M/000001.mp4
---2pGwkL7M/000001.mp4.json
---2pGwkL7M/000002.info.json
---2pGwkL7M/000002.mp4
---2pGwkL7M/000002.mp4.json
---2pGwkL7M/000003.info.json
tar: write error
</code></pre>
<p>These clips have been uploaded to <code>gs://nvdata-ytsamples/yt8m-clips-{000000..000009}.tar</code>.</p>
<h1 id="processing-many-shards-in-parallel">Processing Many Shards in Parallel</h1>
<p>One of the benefits of sharding is that you can process them in parallel. The YT8m-lo dataset consists of 3000 shards with about 2000 videos each. To process them in parallel, you can use standard tools. You need to modify the script a little to take a shard name and to upload the result into a common bucket.</p>
<pre><code class="language-Bash"># splitshard.sh
gsutil cat gs://lpr-yt8m-lo-sharded/yt8m-lo-$1.tar |
tarp proc -m $(pwd)/extract-segments.sh - -o - |
tarp split - -o yt8m-clips-$1-%06d.tar -p 'gsutil cp %s gs://my-output/%s &amp;&amp; rm -f %s`
</code></pre>
<p>On a single machine, you could run run this script with:</p>
<pre><code class="language-Bash">for shard in {000000..003000}; do echo $shard; done |
xargs -i bash splitshard.sh $shard
</code></pre>
<p>More likely, you are going to run a job of this size in the cluster, using Kubernetes or some other job queuing program. Generally, you need to create a Docker container containing the above script (and all dependencies), and then submit it with a simple loop again:</p>
<pre><code class="language-Bash">for shard in {000000..003000}; do echo $shard; done |
submit-job --container=splitshard-container $1
</code></pre>
<p>If you store your shards on AIStore, you can also simply tell AIStore to transform a set of shards using the <code>splitshard-container</code> for you.</p>
<pre><code class="language-python">
</code></pre>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="http://github.com/webdataset/webdataset/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
