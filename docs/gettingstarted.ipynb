{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "WebDataset reads dataset that are stored as tar files, with the simple convention that files that belong together and make up a training sample share the same basename. WebDataset can read files from local disk or from any pipe, which allows it to access files using common cloud object stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e39871fd9fd74f55.jpg\n",
      "e39871fd9fd74f55.json\n",
      "f18b91585c4d3f3e.jpg\n",
      "f18b91585c4d3f3e.json\n",
      "ede6e66b2fb59aab.jpg\n",
      "ede6e66b2fb59aab.json\n",
      "ed600d57fcee4f94.jpg\n",
      "ed600d57fcee4f94.json\n",
      "ff47e649b23f446d.jpg\n",
      "ff47e649b23f446d.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s http://storage.googleapis.com/nvdata-openimages/openimages-train-000000.tar | tar tf - | sed 10q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "from torchvision import transforms\n",
    "import webdataset as wds\n",
    "from itertools import islice\n",
    "\n",
    "url = \"http://storage.googleapis.com/nvdata-openimages/openimages-train-000000.tar\"\n",
    "url = f\"pipe:curl -L -s {url} || true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, let's use the `webdataset.Dataset` class to illustrate how the `webdataset` library works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__key__ 'e39871fd9fd74f55'\n",
      "jpg b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01\n",
      "json b'[{\"ImageID\": \"e39871fd9fd74f55\", \"Source\": \"xcli\n",
      "\n",
      "__key__ 'f18b91585c4d3f3e'\n",
      "jpg b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\n",
      "json b'[{\"ImageID\": \"f18b91585c4d3f3e\", \"Source\": \"acti\n",
      "\n",
      "__key__ 'ede6e66b2fb59aab'\n",
      "jpg b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00\n",
      "json b'[{\"ImageID\": \"ede6e66b2fb59aab\", \"Source\": \"acti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = wds.WebDataset(url)\n",
    "\n",
    "for sample in islice(dataset, 0, 3):\n",
    "    for key, value in sample.items():\n",
    "        print(key, repr(value)[:50])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are common processing stages you can add to a dataset to make it a drop-in replacement for any existing dataset. For convenience, common operations are available through a \"fluent\" interface (as chained method calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 1024, 3) float32 <class 'list'>\n",
      "(768, 1024, 3) float32 <class 'list'>\n",
      "(542, 1024, 3) float32 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "dataset = (\n",
    "    wds.WebDataset(url)\n",
    "    .shuffle(100)\n",
    "    .decode(\"rgb\")\n",
    "    .to_tuple(\"jpg;png\", \"json\")\n",
    ")\n",
    "\n",
    "for image, data in islice(dataset, 0, 3):\n",
    "    print(image.shape, image.dtype, type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `webdataset.Dataset` class has some common operations:\n",
    "\n",
    "- `shuffle(n)`: shuffle the dataset with a buffer of size `n`; also shuffles shards (see below)\n",
    "- `decode(decoder, ...)`: automatically decode files (most commonly, you can just specify `\"pil\"`, `\"rgb\"`, `\"rgb8\"`, `\"rgbtorch\"`, etc.)\n",
    "- `rename(new=\"old1;old2\", ...)`: rename fields\n",
    "- `map(f)`: apply `f` to each sample\n",
    "- `map_dict(key=f, ...)`: apply `f` to its corresponding key\n",
    "- `map_tuple(f, g, ...)`: apply `f`, `g`, etc. to their corresponding values in the tuple\n",
    "- `pipe(f)`: `f` should be a function that takes an iterator and returns a new iterator\n",
    "\n",
    "Stages commonly take a `handler=` argument, which is a function that gets called when there is an exception; you can write whatever function you want, but common functions are:\n",
    "\n",
    "- `webdataset.ignore_and_stop`\n",
    "- `webdataset.ignore_and_continue`\n",
    "- `webdataset.warn_and_stop`\n",
    "- `webdataset.warn_and_continue`\n",
    "- `webdataset.reraise_exception`\n",
    "\n",
    "\n",
    "Here is an example that uses `torchvision` data augmentation the same way you might use it with a `FileDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) torch.float32 <class 'list'>\n",
      "torch.Size([3, 224, 224]) torch.float32 <class 'list'>\n",
      "torch.Size([3, 224, 224]) torch.float32 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preproc = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "dataset = (\n",
    "    wds.WebDataset(url)\n",
    "    .shuffle(100)\n",
    "    .decode(\"pil\")\n",
    "    .to_tuple(\"jpg;png\", \"json\")\n",
    "    .map_tuple(preproc, identity)\n",
    ")\n",
    "\n",
    "for image, data in islice(dataset, 0, 3):\n",
    "    print(image.shape, image.dtype, type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the full PyTorch ImageNet sample code converted to WebDataset at [tmbdev/pytorch-imagenet-wds](http://github.com/tmbdev/pytorch-imagenet-wds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
