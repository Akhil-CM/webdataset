<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Desktop Usage - webdataset</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../css/theme.css" />
  <link rel="stylesheet" href="../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Desktop Usage";
    var mkdocs_page_input_path = "desktop.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> webdataset</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="" href="../api/index.html">API</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Examples</span></p>
                <ul class="current">
                    <li class="toctree-l1"><a class="reference internal" href="../gettingstarted/">Getting Started</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../creating/">Creating Webdatasets</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../decoding/">Decoding</a>
                    </li>
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Desktop Usage</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#direct-copying-of-shards">Direct Copying of Shards</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#automatic-shard-caching">Automatic Shard Caching</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#automatic-sample-caching">Automatic Sample Caching</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../howitworks/">How It Works</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../multinode/">Multinode</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../sharding/">Sharding</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../sources/">Sources</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../writing/">Writing</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../video-loading-example/">Video Loading</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Dataset Conversions</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../convert-falling-things/">Falling Things</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../convert-objectron/">Objectron</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">webdataset</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Examples &raquo;</li>
        
      
    
    <li>Desktop Usage</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="http://github.com/webdataset/webdataset/edit/master/docs/desktop.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <pre><code class="language-python">%pylab inline

import torch
from torch.utils.data import IterableDataset
from torchvision import transforms
import webdataset as wds
from itertools import islice

url = &quot;http://storage.googleapis.com/nvdata-openimages/openimages-train-000000.tar&quot;
url = f&quot;pipe:curl -L -s {url} || true&quot;
</code></pre>
<pre><code>Populating the interactive namespace from numpy and matplotlib
</code></pre>
<h1 id="desktop-usage-and-caching">Desktop Usage and Caching</h1>
<p>WebDataset is an ideal solution for training on petascale datasets kept on high performance distributed data stores like AIStore, AWS/S3, and Google Cloud. Compared to data center GPU servers, desktop machines have much slower network connections, but training jobs on desktop machines often also use much smaller datasets. WebDataset also is very useful for such smaller datasets, and it can easily be used for developing and testing on small datasets and then scaling up to large datasets by simply using more shards.</p>
<p>Here are different usage scenarios:</p>
<table>
<thead>
<tr>
<th>environment</th>
<th>caching strategy</th>
</tr>
</thead>
<tbody>
<tr>
<td>cloud training against cloud buckets</td>
<td>use WebDataset directly with cloud URLs</td>
</tr>
<tr>
<td>on premises training with high performance store (e.g., AIStore)</td>
<td>use WebDataset directly with storage URLs.</td>
</tr>
<tr>
<td>prototyping, development, testing for large scale training</td>
<td>copy a few shards to local disk OR use automatic shard caching OR use DBCache</td>
</tr>
<tr>
<td>on premises training with slower object stores/networks</td>
<td>use automatic shard caching or DBCache for entire dataset</td>
</tr>
<tr>
<td>desktop deep learning, smaller dataset</td>
<td>copy all shards to disk manually OR use automatic shard caching</td>
</tr>
<tr>
<td>training with IterableDataset sources other than WebDataset</td>
<td>use DBCache</td>
</tr>
</tbody>
</table>
<p><em>The upshot is: you can write a single I/O pipeline that works for both local and remote data, and for both small and large datasets, and you can fine-tune performance and take advantage of local storage by adding the <code>cache_dir</code> and <code>DBCache</code> options.</em></p>
<p>Let's look at how these different methods work.</p>
<h2 id="direct-copying-of-shards">Direct Copying of Shards</h2>
<p>Let's take the OpenImages dataset as an example; it's half a terabyte large. For development and testing, you may not want to download the entire dataset, but you may also not want to use the dataset remotely. With WebDataset, you can just download a small number of shards and use them during development.</p>
<pre><code class="language-python">!test -f /tmp/openimages-train-000000.tar || curl -L -s http://storage.googleapis.com/nvdata-openimages/openimages-train-000000.tar &gt; /tmp/openimages-train-000000.tar
</code></pre>
<pre><code class="language-python">dataset = wds.WebDataset(&quot;/tmp/openimages-train-000000.tar&quot;)
repr(next(iter(dataset)))[:200]
</code></pre>
<pre><code>"{'__key__': 'e39871fd9fd74f55', 'jpg': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01:\\x01:\\x00\\x00\\xff\\xdb\\x00C\\x00\\x06\\x04\\x05\\x06\\x05\\x04\\x06\\x06\\x05\\x06\\x07\\x07\\x06\\x08\\n\\x10\\n\\n\\t\\t\\n\\x14\\x0e"
</code></pre>
<p>Note that the WebDataset class works the same way on local files as it does on remote files. Furthermore, unlike other kinds of dataset formats and archive formats, downloaded datasets are immediately useful and don't need to be unpacked.</p>
<h2 id="automatic-shard-caching">Automatic Shard Caching</h2>
<p>Downloading a few shards manually is useful for development and testing. But WebDataset permits us to automate downloading and caching of shards. This is accomplished by giving a <code>cache_dir</code> argument to the WebDataset constructor. Note that caching happens in parallel with iterating through the dataset. This means that if you write a WebDataset-based I/O pipeline, training starts immediately; the training job does not have to wait for any shards to download first.</p>
<p>Automatic shard caching is useful for distributing deep learning code, for academic computer labs, and for cloud computing.</p>
<p>In this example, we make two passes through the dataset, using the cached version on the second pass.</p>
<pre><code class="language-python">!rm -rf ./cache

# just using one URL for demonstration
url = &quot;http://storage.googleapis.com/nvdata-openimages/openimages-train-000000.tar&quot;
dataset = wds.WebDataset(url, cache_dir=&quot;./cache&quot;)

print(&quot;=== first pass&quot;)

for sample in dataset:
    pass

print(&quot;=== second pass&quot;)

for i, sample in enumerate(dataset):
    for key, value in sample.items():
        print(key, repr(value)[:50])
    print()
    if i &gt;= 3: break

!ls -l ./cache
</code></pre>
<pre><code>[caching &lt;webdataset.gopen.Pipe object at 0x7fe2832feaf0&gt; at ./cache/9fd87fa8-d42e-3be4-a3a6-839de961b98a.~2601956~ ]


=== first pass


[done caching ./cache/9fd87fa8-d42e-3be4-a3a6-839de961b98a ]
[finished ./cache/9fd87fa8-d42e-3be4-a3a6-839de961b98a]
[opening cached ./cache/9fd87fa8-d42e-3be4-a3a6-839de961b98a ]


=== second pass
__key__ 'e39871fd9fd74f55'
jpg b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x01\x01
json b'[{"ImageID": "e39871fd9fd74f55", "Source": "xcli

__key__ 'f18b91585c4d3f3e'
jpg b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x00\x00
json b'[{"ImageID": "f18b91585c4d3f3e", "Source": "acti

__key__ 'ede6e66b2fb59aab'
jpg b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x01\x00
json b'[{"ImageID": "ede6e66b2fb59aab", "Source": "acti

__key__ 'ed600d57fcee4f94'
jpg b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x01\x01
json b'[{"ImageID": "ed600d57fcee4f94", "Source": "acti

total 987924
-rw-rw-r-- 1 tmb tmb 1011630080 Nov  2 09:44 9fd87fa8-d42e-3be4-a3a6-839de961b98a
</code></pre>
<p>Using automatic shard caching, you end up with bit-identical copies of the original dataset in the local shard cache. By default, shards are named based on a MD5 checksum of their original URL. If you want to reuse the downloaded cached files, you can override the cache file naming with the <code>cache_name=</code> argument to <code>WebDataset</code> and <code>DBCache</code>.</p>
<p>You can disable shard caching by setting the shard cache directory name to <code>None</code>.</p>
<h2 id="automatic-sample-caching">Automatic Sample Caching</h2>
<p>WebDataset also provides a way of caching training samples directly. This works with samples coming from any IterableDataset as input. The cache is stored in an SQLite3 database. Sample-based caching is implemented by the <code>DBCache</code> class. You specify a filename for the database and the maximum number of samples you want to cache. Samples will initially be read from the original IterableDataset, but after either the samples run out or the maximum number of samples has been reached, subsequently, samples will be served from the database cache stored on local disk. The database cache persists between invocations of the job.</p>
<p>Automatic sample caching is useful for developing and testing deep learning jobs, as well as for caching data coming from slow IterableDataset sources, such as network-based database connections or other slower data sources.</p>
<pre><code class="language-python">!rm -rf ./cache.db

dataset = wds.WebDataset(url).compose(wds.DBCache, &quot;./cache.db&quot;, 1000)

print(&quot;=== first pass&quot;)

for sample in dataset:
    pass

print(&quot;=== second pass&quot;)

for i, sample in enumerate(dataset):
    for key, value in sample.items():
        print(key, repr(value)[:50])
    print()
    if i &gt;= 3: break

!ls -l ./cache.db
</code></pre>
<pre><code>[DBCache opened ./cache.db size 1000 total 0]
[DBCache total 0 size 1000 more caching]


=== first pass


[DBCache finished caching total 1000 (size 1000)]
[DBCache starting dbiter total 1000 size 1000]


=== second pass
__key__ 'e39871fd9fd74f55'
jpg b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x01\x01
json b'[{"ImageID": "e39871fd9fd74f55", "Source": "xcli

__key__ 'f18b91585c4d3f3e'
jpg b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x00\x00
json b'[{"ImageID": "f18b91585c4d3f3e", "Source": "acti

__key__ 'ede6e66b2fb59aab'
jpg b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x01\x00
json b'[{"ImageID": "ede6e66b2fb59aab", "Source": "acti

__key__ 'ed600d57fcee4f94'
jpg b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x01\x01
json b'[{"ImageID": "ed600d57fcee4f94", "Source": "acti

-rw-r--r-- 1 tmb tmb 485199872 Nov  2 09:44 ./cache.db
</code></pre>
<p>You can disable the cache by changing the cache file name to <code>None</code>. This makes it easy to enable/disable the cache for testing.</p>
<p>Sample-based caching using <code>DBCache</code> gives you more flexibility than shard-based caching: you can cache before or after decoding and before or after data augmentation. However, unlike shard-based caching, the cache won't be considered "complete" until the number of cached samples requested have been cached. The <code>DBCache</code> class is primarily useful for testing, and for caching data that comes from <code>IterableDataset</code> sources other than <code>WebDataset</code>.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../howitworks/" class="btn btn-neutral float-right" title="How It Works">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../decoding/" class="btn btn-neutral" title="Decoding"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="http://github.com/webdataset/webdataset/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../decoding/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../howitworks/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
