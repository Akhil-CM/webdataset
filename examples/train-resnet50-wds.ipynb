{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 50 Training on (Fake)Imagenet with WebDataset\n",
    "\n",
    "This notebook illustrates how to use WebDataset with PyTorch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "\n",
    "# helpers\n",
    "\n",
    "import time\n",
    "\n",
    "def enumerate_report(seq, delta, growth=1.0):\n",
    "    last = 0\n",
    "    count = 0\n",
    "    for count, item in enumerate(seq):\n",
    "        now = time.time()\n",
    "        if now - last > delta:\n",
    "            last = now\n",
    "            yield count, item, True\n",
    "        else:\n",
    "            yield count, item, False\n",
    "        delta *= growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We usually abbreviate webdataset as wds\n",
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The source of the dataset.\n",
    "\n",
    "bucket = \"https://storage.googleapis.com/webdataset/fake-imagenet\"\n",
    "training_urls = bucket + \"/imagenet-train-{000000..001281}.tar\"\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not running in colab, caching data locally in ./_cache\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# WebDataset is designed to work without any local storage. Use caching\n",
    "# only if you are on a desktop with slow networking.\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    cache_dir = None\n",
    "    print(\"running on colab, streaming data directly from storage\")\n",
    "else:\n",
    "    !mkdir -p ./_cache\n",
    "    cache_dir = \"./_cache\"\n",
    "    print(f\"not running in colab, caching data locally in {cache_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The standard TorchVision transformations.\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def make_sample(sample, val=False):\n",
    "    \"\"\"Take a decoded sample dictionary, augment it, and return an (image, label) tuple.\"\"\"\n",
    "    assert not val, \"only implemented training dataset for this notebook\"\n",
    "    image = sample[\"jpg\"]\n",
    "    label = sample[\"cls\"]\n",
    "    return transform_train(image), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the datasets with shard and sample shuffling and decoding.\n",
    "trainset = wds.WebDataset(training_urls, resampled=True, cache_dir=cache_dir, shardshuffle=True)\n",
    "trainset = trainset.shuffle(1000).decode(\"pil\").map(make_sample)\n",
    "\n",
    "# Since this is an IterableDataset, PyTorch requires that we batch in the dataset.\n",
    "# WebLoader is PyTorch DataLoader with some convenience methods.\n",
    "trainset = trainset.batched(64)\n",
    "trainloader = wds.WebLoader(trainset, batch_size=None, num_workers=4)\n",
    "\n",
    "# Unbatch, shuffle between workers, then rebatch.\n",
    "trainloader = trainloader.unbatched().shuffle(1000).batched(64)\n",
    "\n",
    "# Since we are using resampling, the dataset is infinite; set an artificial epoch size.\n",
    "trainloader = trainloader.with_epoch(1282 * 100 // 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GOPENGOPEN  https://storage.googleapis.com/webdataset/fake-imagenet/imagenet-train-000860.tarhttps://storage.googleapis.com/webdataset/fake-imagenet/imagenet-train-000233.tar  {}{}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pipe exit [0 2416815:2416868] ((\"curl -f -s -L 'https://storage.googleapis.com/webdataset/fake-imagenet/imagenet-train-000233.tar'\",), {'shell': True, 'bufsize': 8192}) {}\n",
      "pipe exit [0 2416803:2416867] ((\"curl -f -s -L 'https://storage.googleapis.com/webdataset/fake-imagenet/imagenet-train-000860.tar'\",), {'shell': True, 'bufsize': 8192}) {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Smoke test it.\n",
    "\n",
    "os.environ[\"GOPEN_VERBOSE\"] = \"1\"\n",
    "images, classes = next(iter(trainloader))\n",
    "print(images.shape, classes.shape)\n",
    "os.environ[\"GOPEN_VERBOSE\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Training\n",
    "\n",
    "This is a typical PyTorch training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# The usual PyTorch model definition. We use an uninitialized ResNet50 model.\n",
    "\n",
    "model = resnet50(pretrained=False)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 4.76379 correct: 0.07656\n",
      "[1,    15] loss: 4.60549 correct: 0.08333\n",
      "[1,    29] loss: 4.22173 correct: 0.09052\n",
      "[1,    43] loss: 3.97581 correct: 0.09339\n",
      "[1,    56] loss: 3.83008 correct: 0.10100\n",
      "[1,    69] loss: 3.63373 correct: 0.11164\n",
      "[1,    82] loss: 3.47505 correct: 0.12957\n",
      "[1,    95] loss: 3.35933 correct: 0.14062\n",
      "[1,   108] loss: 3.11937 correct: 0.16156\n",
      "[1,   121] loss: 2.83944 correct: 0.19672\n",
      "[1,   134] loss: 2.66036 correct: 0.22766\n",
      "[1,   148] loss: 2.44853 correct: 0.27234\n",
      "[1,   162] loss: 2.28026 correct: 0.31734\n",
      "[1,   172] loss: 2.19525 correct: 0.34359\n",
      "[1,   186] loss: 2.08001 correct: 0.37703\n",
      "[1,   199] loss: 1.98180 correct: 0.40766\n",
      "[1,   213] loss: 1.87447 correct: 0.43688\n",
      "[1,   226] loss: 1.80813 correct: 0.45969\n",
      "[1,   239] loss: 1.73008 correct: 0.48750\n",
      "[1,   252] loss: 1.65877 correct: 0.49906\n",
      "[1,   266] loss: 1.59890 correct: 0.51203\n",
      "[1,   280] loss: 1.53183 correct: 0.53031\n",
      "[1,   293] loss: 1.45920 correct: 0.54719\n",
      "[1,   300] loss: 1.43194 correct: 0.55563\n",
      "[1,   313] loss: 1.39472 correct: 0.56734\n",
      "[1,   326] loss: 1.35438 correct: 0.57656\n",
      "[1,   339] loss: 1.33005 correct: 0.57891\n",
      "[1,   352] loss: 1.31005 correct: 0.58719\n",
      "[1,   360] loss: 1.29459 correct: 0.59203\n",
      "[1,   373] loss: 1.26345 correct: 0.60078\n",
      "[1,   386] loss: 1.22962 correct: 0.61313\n",
      "[1,   399] loss: 1.21200 correct: 0.61953\n",
      "[1,   413] loss: 1.16715 correct: 0.63578\n",
      "[1,   426] loss: 1.13689 correct: 0.64375\n",
      "[1,   439] loss: 1.09549 correct: 0.65781\n",
      "[1,   452] loss: 1.07969 correct: 0.66391\n",
      "[1,   465] loss: 1.07799 correct: 0.66781\n",
      "[1,   478] loss: 1.07528 correct: 0.67328\n",
      "[1,   491] loss: 1.07596 correct: 0.67484\n",
      "[1,   504] loss: 1.07124 correct: 0.67563\n",
      "[1,   517] loss: 1.05779 correct: 0.67672\n",
      "[1,   530] loss: 1.05141 correct: 0.67594\n",
      "[1,   543] loss: 1.04447 correct: 0.67937\n",
      "[1,   553] loss: 1.02656 correct: 0.68531\n",
      "[1,   566] loss: 1.00715 correct: 0.68937\n",
      "[1,   580] loss: 0.95896 correct: 0.70047\n",
      "[1,   594] loss: 0.92024 correct: 0.71297\n",
      "[1,   607] loss: 0.89296 correct: 0.72156\n",
      "[1,   621] loss: 0.89670 correct: 0.72484\n",
      "[1,   635] loss: 0.89215 correct: 0.72609\n",
      "[1,   648] loss: 0.88309 correct: 0.73047\n",
      "[1,   661] loss: 0.86844 correct: 0.73625\n",
      "[1,   674] loss: 0.85286 correct: 0.73875\n",
      "[1,   687] loss: 0.84789 correct: 0.73766\n",
      "[1,   701] loss: 0.84218 correct: 0.74062\n",
      "[1,   714] loss: 0.81609 correct: 0.74938\n",
      "[1,   727] loss: 0.79753 correct: 0.75406\n",
      "[1,   740] loss: 0.77087 correct: 0.76406\n",
      "[1,   754] loss: 0.77254 correct: 0.76484\n",
      "[1,   767] loss: 0.76092 correct: 0.76750\n",
      "[1,   781] loss: 0.77086 correct: 0.76687\n",
      "[1,   794] loss: 0.78027 correct: 0.76297\n",
      "[1,   807] loss: 0.78936 correct: 0.76328\n",
      "[1,   820] loss: 0.79547 correct: 0.76313\n",
      "[1,   833] loss: 0.78520 correct: 0.76844\n",
      "[1,   846] loss: 0.78681 correct: 0.76922\n",
      "[1,   859] loss: 0.77762 correct: 0.77203\n",
      "[1,   872] loss: 0.76141 correct: 0.77812\n",
      "[1,   885] loss: 0.73267 correct: 0.78531\n",
      "[1,   899] loss: 0.72179 correct: 0.78797\n",
      "[1,   913] loss: 0.71451 correct: 0.78734\n",
      "[1,   923] loss: 0.71704 correct: 0.78750\n",
      "[1,   936] loss: 0.72303 correct: 0.78406\n",
      "[1,   950] loss: 0.72010 correct: 0.78172\n",
      "[1,   963] loss: 0.73144 correct: 0.77687\n",
      "[1,   977] loss: 0.75904 correct: 0.76703\n",
      "[1,   991] loss: 0.74225 correct: 0.77312\n",
      "[1,  1004] loss: 0.73010 correct: 0.77297\n",
      "[1,  1017] loss: 0.73306 correct: 0.77031\n",
      "[1,  1030] loss: 0.70454 correct: 0.77703\n",
      "[1,  1043] loss: 0.69265 correct: 0.78156\n",
      "[1,  1047] loss: 0.68855 correct: 0.78328\n",
      "[1,  1061] loss: 0.66805 correct: 0.79281\n",
      "[1,  1075] loss: 0.63608 correct: 0.80078\n",
      "[1,  1088] loss: 0.63216 correct: 0.80281\n",
      "[1,  1101] loss: 0.63312 correct: 0.80469\n",
      "[1,  1113] loss: 0.61758 correct: 0.81047\n",
      "[1,  1126] loss: 0.60149 correct: 0.81563\n",
      "[1,  1139] loss: 0.60150 correct: 0.81781\n",
      "[1,  1153] loss: 0.59639 correct: 0.81906\n",
      "[1,  1166] loss: 0.59695 correct: 0.81969\n",
      "[1,  1172] loss: 0.58893 correct: 0.82312\n",
      "[1,  1185] loss: 0.58603 correct: 0.82328\n",
      "[1,  1198] loss: 0.57071 correct: 0.82547\n",
      "[1,  1211] loss: 0.57803 correct: 0.82203\n",
      "[1,  1224] loss: 0.57244 correct: 0.82516\n",
      "[1,  1235] loss: 0.55930 correct: 0.82797\n",
      "[1,  1236] loss: 0.55870 correct: 0.82859\n",
      "[1,  1250] loss: 0.55067 correct: 0.83172\n",
      "[1,  1264] loss: 0.56348 correct: 0.82578\n",
      "[1,  1277] loss: 0.55727 correct: 0.82859\n",
      "[1,  1290] loss: 0.57181 correct: 0.82328\n",
      "[1,  1302] loss: 0.57537 correct: 0.82422\n",
      "[1,  1316] loss: 0.57865 correct: 0.82484\n",
      "[1,  1329] loss: 0.60102 correct: 0.81797\n",
      "[1,  1343] loss: 0.60679 correct: 0.81578\n",
      "[1,  1356] loss: 0.59891 correct: 0.81906\n",
      "[1,  1369] loss: 0.58639 correct: 0.82266\n",
      "[1,  1382] loss: 0.57059 correct: 0.82531\n",
      "[1,  1395] loss: 0.57553 correct: 0.82828\n",
      "[1,  1408] loss: 0.57033 correct: 0.82734\n",
      "[1,  1421] loss: 0.56845 correct: 0.82922\n",
      "[1,  1434] loss: 0.56348 correct: 0.82875\n",
      "[1,  1447] loss: 0.56370 correct: 0.83109\n",
      "[1,  1460] loss: 0.56697 correct: 0.82547\n",
      "[1,  1473] loss: 0.56151 correct: 0.82703\n",
      "[1,  1483] loss: 0.55344 correct: 0.82609\n",
      "[1,  1496] loss: 0.54044 correct: 0.82812\n",
      "[1,  1510] loss: 0.52694 correct: 0.83094\n",
      "[1,  1523] loss: 0.51378 correct: 0.83391\n",
      "[1,  1537] loss: 0.50836 correct: 0.83484\n",
      "[1,  1550] loss: 0.49641 correct: 0.83734\n",
      "[1,  1564] loss: 0.48896 correct: 0.84281\n",
      "[1,  1578] loss: 0.48124 correct: 0.84656\n",
      "[1,  1591] loss: 0.49391 correct: 0.84641\n",
      "[1,  1604] loss: 0.49410 correct: 0.84672\n",
      "[1,  1612] loss: 0.49359 correct: 0.84719\n",
      "[1,  1625] loss: 0.49598 correct: 0.84344\n",
      "[1,  1638] loss: 0.49123 correct: 0.84328\n",
      "[1,  1651] loss: 0.47634 correct: 0.85062\n",
      "[1,  1664] loss: 0.47821 correct: 0.84969\n",
      "[1,  1672] loss: 0.48439 correct: 0.84906\n",
      "[1,  1685] loss: 0.46946 correct: 0.85266\n",
      "[1,  1698] loss: 0.45675 correct: 0.85500\n",
      "[1,  1712] loss: 0.45702 correct: 0.85437\n",
      "[1,  1725] loss: 0.44986 correct: 0.85953\n",
      "[1,  1738] loss: 0.44515 correct: 0.86359\n",
      "[1,  1751] loss: 0.46210 correct: 0.85891\n",
      "[1,  1764] loss: 0.46054 correct: 0.85844\n",
      "[1,  1777] loss: 0.47170 correct: 0.85594\n",
      "[1,  1791] loss: 0.47382 correct: 0.85625\n",
      "[1,  1805] loss: 0.45981 correct: 0.86250\n",
      "[1,  1818] loss: 0.45095 correct: 0.86625\n",
      "[1,  1832] loss: 0.44353 correct: 0.86859\n",
      "[1,  1845] loss: 0.44589 correct: 0.86703\n",
      "[1,  1858] loss: 0.44398 correct: 0.86969\n",
      "[1,  1871] loss: 0.45279 correct: 0.86516\n",
      "[1,  1884] loss: 0.44506 correct: 0.86656\n",
      "[1,  1897] loss: 0.43479 correct: 0.86953\n",
      "[1,  1910] loss: 0.44721 correct: 0.86656\n",
      "[1,  1923] loss: 0.45925 correct: 0.86516\n",
      "[1,  1936] loss: 0.46247 correct: 0.86203\n",
      "[1,  1949] loss: 0.45013 correct: 0.86562\n",
      "[1,  1962] loss: 0.44417 correct: 0.86562\n",
      "[1,  1976] loss: 0.44046 correct: 0.86797\n",
      "[1,  1989] loss: 0.43573 correct: 0.86828\n",
      "[1,  2002] loss: 0.43884 correct: 0.86734\n",
      "[2,     1] loss: 0.43851 correct: 0.86687\n",
      "[2,    14] loss: 0.44188 correct: 0.86672\n",
      "[2,    28] loss: 0.43834 correct: 0.86703\n",
      "[2,    42] loss: 0.44194 correct: 0.86625\n",
      "[2,    56] loss: 0.45297 correct: 0.86391\n",
      "[2,    70] loss: 0.43947 correct: 0.86594\n",
      "[2,    83] loss: 0.44748 correct: 0.86438\n",
      "[2,    97] loss: 0.45891 correct: 0.85938\n",
      "[2,   111] loss: 0.45223 correct: 0.86062\n",
      "[2,   124] loss: 0.44569 correct: 0.86094\n",
      "[2,   137] loss: 0.45312 correct: 0.85891\n",
      "[2,   150] loss: 0.45435 correct: 0.85750\n",
      "[2,   163] loss: 0.44816 correct: 0.85781\n",
      "[2,   176] loss: 0.43963 correct: 0.86156\n",
      "[2,   189] loss: 0.44104 correct: 0.86000\n",
      "[2,   202] loss: 0.42888 correct: 0.86547\n",
      "[2,   215] loss: 0.43115 correct: 0.86406\n",
      "[2,   228] loss: 0.42630 correct: 0.86625\n",
      "[2,   241] loss: 0.41928 correct: 0.86813\n",
      "[2,   254] loss: 0.40429 correct: 0.87250\n",
      "[2,   267] loss: 0.39632 correct: 0.87500\n",
      "[2,   280] loss: 0.39395 correct: 0.87828\n",
      "[2,   294] loss: 0.39013 correct: 0.87906\n",
      "[2,   307] loss: 0.39041 correct: 0.87953\n",
      "[2,   320] loss: 0.37818 correct: 0.88328\n",
      "[2,   333] loss: 0.37278 correct: 0.88516\n",
      "[2,   346] loss: 0.37330 correct: 0.88500\n",
      "[2,   359] loss: 0.37828 correct: 0.88422\n",
      "[2,   372] loss: 0.38567 correct: 0.88344\n",
      "[2,   385] loss: 0.37374 correct: 0.88484\n",
      "[2,   398] loss: 0.37318 correct: 0.88391\n",
      "[2,   411] loss: 0.36487 correct: 0.88656\n",
      "[2,   423] loss: 0.35627 correct: 0.88984\n",
      "[2,   436] loss: 0.35256 correct: 0.89094\n",
      "[2,   450] loss: 0.35410 correct: 0.89359\n",
      "[2,   463] loss: 0.34336 correct: 0.89438\n",
      "[2,   476] loss: 0.33463 correct: 0.89719\n",
      "[2,   489] loss: 0.34197 correct: 0.89609\n",
      "[2,   502] loss: 0.33491 correct: 0.89906\n",
      "[2,   516] loss: 0.34220 correct: 0.89453\n",
      "[2,   529] loss: 0.34360 correct: 0.89312\n",
      "[2,   543] loss: 0.34057 correct: 0.89219\n",
      "[2,   556] loss: 0.34522 correct: 0.89125\n",
      "[2,   570] loss: 0.35656 correct: 0.88922\n",
      "[2,   583] loss: 0.36134 correct: 0.88813\n",
      "[2,   597] loss: 0.36484 correct: 0.88719\n",
      "[2,   610] loss: 0.35955 correct: 0.88859\n",
      "[2,   623] loss: 0.35512 correct: 0.89172\n",
      "[2,   637] loss: 0.35358 correct: 0.89406\n",
      "[2,   650] loss: 0.35240 correct: 0.89391\n",
      "[2,   664] loss: 0.34068 correct: 0.89609\n",
      "[2,   677] loss: 0.33695 correct: 0.89828\n",
      "[2,   690] loss: 0.33858 correct: 0.89594\n",
      "[2,   703] loss: 0.33239 correct: 0.89922\n",
      "[2,   716] loss: 0.34239 correct: 0.89516\n",
      "[2,   730] loss: 0.35157 correct: 0.89047\n",
      "[2,   744] loss: 0.35016 correct: 0.88844\n",
      "[2,   757] loss: 0.34296 correct: 0.88906\n",
      "[2,   770] loss: 0.35407 correct: 0.88500\n",
      "[2,   783] loss: 0.36243 correct: 0.88281\n",
      "[2,   796] loss: 0.34981 correct: 0.88641\n",
      "[2,   809] loss: 0.34517 correct: 0.88734\n",
      "[2,   822] loss: 0.32812 correct: 0.89484\n",
      "[2,   835] loss: 0.32400 correct: 0.89594\n",
      "[2,   848] loss: 0.33617 correct: 0.89281\n",
      "[2,   861] loss: 0.33773 correct: 0.89344\n",
      "[2,   874] loss: 0.33960 correct: 0.89250\n",
      "[2,   887] loss: 0.33443 correct: 0.89125\n",
      "[2,   900] loss: 0.34064 correct: 0.88891\n",
      "[2,   913] loss: 0.33309 correct: 0.89000\n",
      "[2,   926] loss: 0.33778 correct: 0.88828\n",
      "[2,   939] loss: 0.33214 correct: 0.89016\n",
      "[2,   952] loss: 0.32274 correct: 0.89219\n",
      "[2,   965] loss: 0.32552 correct: 0.89125\n",
      "[2,   978] loss: 0.32771 correct: 0.89062\n",
      "[2,   992] loss: 0.32918 correct: 0.89172\n",
      "[2,  1005] loss: 0.33575 correct: 0.89156\n",
      "[2,  1018] loss: 0.34552 correct: 0.89000\n",
      "[2,  1032] loss: 0.35015 correct: 0.88859\n",
      "[2,  1045] loss: 0.34392 correct: 0.89141\n",
      "[2,  1058] loss: 0.34228 correct: 0.89344\n",
      "[2,  1071] loss: 0.33498 correct: 0.89766\n",
      "[2,  1084] loss: 0.33247 correct: 0.89812\n",
      "[2,  1097] loss: 0.32733 correct: 0.90047\n",
      "[2,  1110] loss: 0.33144 correct: 0.89891\n",
      "[2,  1123] loss: 0.33587 correct: 0.89703\n",
      "[2,  1136] loss: 0.32807 correct: 0.89875\n",
      "[2,  1149] loss: 0.33398 correct: 0.89625\n",
      "[2,  1162] loss: 0.32559 correct: 0.89812\n",
      "[2,  1175] loss: 0.32239 correct: 0.89859\n",
      "[2,  1188] loss: 0.32207 correct: 0.89891\n",
      "[2,  1201] loss: 0.31566 correct: 0.90109\n",
      "[2,  1214] loss: 0.30898 correct: 0.90344\n",
      "[2,  1227] loss: 0.30946 correct: 0.90578\n",
      "[2,  1240] loss: 0.31280 correct: 0.90438\n",
      "[2,  1253] loss: 0.30407 correct: 0.90625\n",
      "[2,  1266] loss: 0.31066 correct: 0.90453\n",
      "[2,  1279] loss: 0.30499 correct: 0.90781\n",
      "[2,  1292] loss: 0.31011 correct: 0.90422\n",
      "[2,  1303] loss: 0.30754 correct: 0.90641\n",
      "[2,  1316] loss: 0.30547 correct: 0.90609\n",
      "[2,  1329] loss: 0.31878 correct: 0.90234\n",
      "[2,  1342] loss: 0.31806 correct: 0.90312\n",
      "[2,  1355] loss: 0.32097 correct: 0.90156\n",
      "[2,  1365] loss: 0.32485 correct: 0.90156\n",
      "[2,  1378] loss: 0.32742 correct: 0.89922\n",
      "[2,  1391] loss: 0.32999 correct: 0.89859\n",
      "[2,  1404] loss: 0.33102 correct: 0.89781\n",
      "[2,  1418] loss: 0.32757 correct: 0.89734\n",
      "[2,  1424] loss: 0.32005 correct: 0.89922\n",
      "[2,  1438] loss: 0.31482 correct: 0.90203\n",
      "[2,  1452] loss: 0.31343 correct: 0.90172\n",
      "[2,  1465] loss: 0.32094 correct: 0.89969\n",
      "[2,  1478] loss: 0.32878 correct: 0.89906\n",
      "[2,  1491] loss: 0.32511 correct: 0.89953\n",
      "[2,  1504] loss: 0.31663 correct: 0.90266\n",
      "[2,  1517] loss: 0.31517 correct: 0.90422\n",
      "[2,  1530] loss: 0.31950 correct: 0.90141\n",
      "[2,  1543] loss: 0.32379 correct: 0.89984\n",
      "[2,  1548] loss: 0.32631 correct: 0.89891\n",
      "[2,  1562] loss: 0.32187 correct: 0.89922\n",
      "[2,  1576] loss: 0.31890 correct: 0.89828\n",
      "[2,  1589] loss: 0.32903 correct: 0.89719\n",
      "[2,  1603] loss: 0.33945 correct: 0.89344\n",
      "[2,  1612] loss: 0.34046 correct: 0.89391\n",
      "[2,  1625] loss: 0.34167 correct: 0.89328\n",
      "[2,  1638] loss: 0.34131 correct: 0.89359\n",
      "[2,  1651] loss: 0.33954 correct: 0.89469\n",
      "[2,  1665] loss: 0.33123 correct: 0.89641\n",
      "[2,  1678] loss: 0.31550 correct: 0.90172\n",
      "[2,  1692] loss: 0.30451 correct: 0.90781\n",
      "[2,  1705] loss: 0.29232 correct: 0.91250\n",
      "[2,  1718] loss: 0.29140 correct: 0.91156\n",
      "[2,  1731] loss: 0.29299 correct: 0.91219\n",
      "[2,  1735] loss: 0.29499 correct: 0.91141\n",
      "[2,  1748] loss: 0.29095 correct: 0.91125\n",
      "[2,  1761] loss: 0.28779 correct: 0.91281\n",
      "[2,  1774] loss: 0.29352 correct: 0.91156\n",
      "[2,  1787] loss: 0.29874 correct: 0.90812\n",
      "[2,  1800] loss: 0.29863 correct: 0.90687\n",
      "[2,  1813] loss: 0.28990 correct: 0.91094\n",
      "[2,  1826] loss: 0.28771 correct: 0.91391\n",
      "[2,  1839] loss: 0.28748 correct: 0.91453\n",
      "[2,  1852] loss: 0.29300 correct: 0.91203\n",
      "[2,  1865] loss: 0.29676 correct: 0.91047\n",
      "[2,  1878] loss: 0.29617 correct: 0.91031\n",
      "[2,  1891] loss: 0.30577 correct: 0.90750\n",
      "[2,  1905] loss: 0.31522 correct: 0.90391\n",
      "[2,  1918] loss: 0.31810 correct: 0.90031\n",
      "[2,  1923] loss: 0.31015 correct: 0.90203\n",
      "[2,  1936] loss: 0.30746 correct: 0.90172\n",
      "[2,  1949] loss: 0.30137 correct: 0.90453\n",
      "[2,  1963] loss: 0.29929 correct: 0.90531\n",
      "[2,  1976] loss: 0.29537 correct: 0.90734\n",
      "[2,  1989] loss: 0.28341 correct: 0.90875\n",
      "[2,  2002] loss: 0.28249 correct: 0.90953\n",
      "[3,     1] loss: 0.28561 correct: 0.90812\n",
      "[3,    14] loss: 0.29580 correct: 0.90641\n",
      "[3,    28] loss: 0.29912 correct: 0.90547\n",
      "[3,    42] loss: 0.31416 correct: 0.90266\n",
      "[3,    56] loss: 0.30917 correct: 0.90641\n",
      "[3,    70] loss: 0.31779 correct: 0.90422\n",
      "[3,    83] loss: 0.31497 correct: 0.90594\n",
      "[3,    97] loss: 0.31010 correct: 0.90703\n",
      "[3,   110] loss: 0.29306 correct: 0.91297\n",
      "[3,   123] loss: 0.27891 correct: 0.91687\n",
      "[3,   137] loss: 0.26875 correct: 0.91812\n",
      "[3,   150] loss: 0.25271 correct: 0.92063\n",
      "[3,   163] loss: 0.24227 correct: 0.92297\n",
      "[3,   170] loss: 0.24229 correct: 0.92328\n",
      "[3,   184] loss: 0.24064 correct: 0.92281\n",
      "[3,   198] loss: 0.23321 correct: 0.92578\n",
      "[3,   211] loss: 0.22567 correct: 0.92875\n",
      "[3,   224] loss: 0.23177 correct: 0.92688\n",
      "[3,   236] loss: 0.23936 correct: 0.92359\n",
      "[3,   249] loss: 0.25229 correct: 0.92031\n",
      "[3,   262] loss: 0.25862 correct: 0.91844\n",
      "[3,   275] loss: 0.25658 correct: 0.91672\n",
      "[3,   288] loss: 0.26331 correct: 0.91703\n",
      "[3,   298] loss: 0.26989 correct: 0.91484\n",
      "[3,   311] loss: 0.27251 correct: 0.91391\n",
      "[3,   325] loss: 0.26690 correct: 0.91531\n",
      "[3,   338] loss: 0.27646 correct: 0.91484\n",
      "[3,   351] loss: 0.27119 correct: 0.91687\n",
      "[3,   360] loss: 0.27509 correct: 0.91594\n",
      "[3,   373] loss: 0.27443 correct: 0.91641\n",
      "[3,   387] loss: 0.27205 correct: 0.91781\n",
      "[3,   400] loss: 0.27411 correct: 0.91797\n",
      "[3,   413] loss: 0.28061 correct: 0.91672\n",
      "[3,   422] loss: 0.28245 correct: 0.91641\n",
      "[3,   424] loss: 0.27963 correct: 0.91703\n",
      "[3,   438] loss: 0.25988 correct: 0.92094\n",
      "[3,   451] loss: 0.25834 correct: 0.92312\n",
      "[3,   464] loss: 0.25832 correct: 0.92297\n",
      "[3,   477] loss: 0.26551 correct: 0.92109\n",
      "[3,   484] loss: 0.26484 correct: 0.92078\n",
      "[3,   498] loss: 0.25497 correct: 0.92297\n",
      "[3,   512] loss: 0.25745 correct: 0.92266\n",
      "[3,   525] loss: 0.26203 correct: 0.92250\n",
      "[3,   539] loss: 0.26796 correct: 0.92047\n",
      "[3,   549] loss: 0.26469 correct: 0.92063\n",
      "[3,   563] loss: 0.26230 correct: 0.92125\n",
      "[3,   576] loss: 0.25558 correct: 0.92188\n",
      "[3,   589] loss: 0.25496 correct: 0.92109\n",
      "[3,   603] loss: 0.26076 correct: 0.91938\n",
      "[3,   615] loss: 0.26161 correct: 0.91844\n",
      "[3,   628] loss: 0.26345 correct: 0.91781\n",
      "[3,   641] loss: 0.26425 correct: 0.91766\n",
      "[3,   654] loss: 0.26087 correct: 0.91812\n",
      "[3,   667] loss: 0.25733 correct: 0.91844\n",
      "[3,   675] loss: 0.26102 correct: 0.91609\n",
      "[3,   689] loss: 0.25772 correct: 0.91734\n",
      "[3,   702] loss: 0.25414 correct: 0.91797\n",
      "[3,   715] loss: 0.24889 correct: 0.91906\n",
      "[3,   728] loss: 0.23967 correct: 0.92031\n",
      "[3,   734] loss: 0.23904 correct: 0.92031\n",
      "[3,   736] loss: 0.23854 correct: 0.92078\n",
      "[3,   750] loss: 0.23736 correct: 0.92094\n",
      "[3,   764] loss: 0.23487 correct: 0.92063\n",
      "[3,   778] loss: 0.23135 correct: 0.92281\n",
      "[3,   792] loss: 0.22654 correct: 0.92391\n",
      "[3,   800] loss: 0.22802 correct: 0.92266\n",
      "[3,   814] loss: 0.22706 correct: 0.92344\n",
      "[3,   828] loss: 0.23424 correct: 0.92234\n",
      "[3,   842] loss: 0.23543 correct: 0.92078\n",
      "[3,   856] loss: 0.23792 correct: 0.92281\n",
      "[3,   859] loss: 0.23683 correct: 0.92297\n",
      "[3,   872] loss: 0.24773 correct: 0.92172\n",
      "[3,   886] loss: 0.25693 correct: 0.91938\n",
      "[3,   900] loss: 0.26277 correct: 0.91906\n",
      "[3,   914] loss: 0.26727 correct: 0.91703\n",
      "[3,   926] loss: 0.26745 correct: 0.91812\n",
      "[3,   940] loss: 0.27858 correct: 0.91687\n",
      "[3,   954] loss: 0.27933 correct: 0.91516\n",
      "[3,   968] loss: 0.27243 correct: 0.91641\n",
      "[3,   982] loss: 0.26815 correct: 0.91922\n",
      "[3,   992] loss: 0.25996 correct: 0.92203\n",
      "[3,  1006] loss: 0.26117 correct: 0.92359\n",
      "[3,  1019] loss: 0.25675 correct: 0.92359\n",
      "[3,  1033] loss: 0.24965 correct: 0.92531\n",
      "[3,  1047] loss: 0.24784 correct: 0.92578\n",
      "[3,  1061] loss: 0.24174 correct: 0.92641\n",
      "[3,  1075] loss: 0.24173 correct: 0.92578\n",
      "[3,  1089] loss: 0.24009 correct: 0.92453\n",
      "[3,  1102] loss: 0.24408 correct: 0.92234\n",
      "[3,  1116] loss: 0.25591 correct: 0.91984\n",
      "[3,  1130] loss: 0.24889 correct: 0.92125\n",
      "[3,  1144] loss: 0.24706 correct: 0.92312\n",
      "[3,  1157] loss: 0.25534 correct: 0.92125\n",
      "[3,  1171] loss: 0.25412 correct: 0.92219\n",
      "[3,  1185] loss: 0.25695 correct: 0.92297\n",
      "[3,  1199] loss: 0.25185 correct: 0.92359\n",
      "[3,  1213] loss: 0.24647 correct: 0.92656\n",
      "[3,  1227] loss: 0.25093 correct: 0.92422\n",
      "[3,  1236] loss: 0.25605 correct: 0.92203\n",
      "[3,  1250] loss: 0.24477 correct: 0.92469\n",
      "[3,  1264] loss: 0.23910 correct: 0.92531\n",
      "[3,  1278] loss: 0.23627 correct: 0.92578\n",
      "[3,  1292] loss: 0.24946 correct: 0.92156\n",
      "[3,  1305] loss: 0.25204 correct: 0.91938\n",
      "[3,  1319] loss: 0.24526 correct: 0.92219\n",
      "[3,  1333] loss: 0.23813 correct: 0.92516\n",
      "[3,  1347] loss: 0.24034 correct: 0.92500\n",
      "[3,  1357] loss: 0.23887 correct: 0.92484\n",
      "[3,  1364] loss: 0.23294 correct: 0.92766\n",
      "[3,  1378] loss: 0.23050 correct: 0.92797\n",
      "[3,  1392] loss: 0.22776 correct: 0.92953\n",
      "[3,  1406] loss: 0.22618 correct: 0.92891\n",
      "[3,  1420] loss: 0.23329 correct: 0.92703\n",
      "[3,  1433] loss: 0.23264 correct: 0.92625\n",
      "[3,  1447] loss: 0.22905 correct: 0.92719\n",
      "[3,  1461] loss: 0.23370 correct: 0.92500\n",
      "[3,  1475] loss: 0.24054 correct: 0.92281\n",
      "[3,  1489] loss: 0.23397 correct: 0.92484\n",
      "[3,  1503] loss: 0.23231 correct: 0.92594\n",
      "[3,  1517] loss: 0.23435 correct: 0.92547\n",
      "[3,  1530] loss: 0.23125 correct: 0.92688\n",
      "[3,  1543] loss: 0.23588 correct: 0.92531\n",
      "[3,  1557] loss: 0.23358 correct: 0.92703\n",
      "[3,  1571] loss: 0.23463 correct: 0.92656\n",
      "[3,  1585] loss: 0.23423 correct: 0.92625\n",
      "[3,  1599] loss: 0.24379 correct: 0.92172\n",
      "[3,  1612] loss: 0.23512 correct: 0.92609\n",
      "[3,  1626] loss: 0.23662 correct: 0.92547\n",
      "[3,  1640] loss: 0.23950 correct: 0.92547\n",
      "[3,  1654] loss: 0.23987 correct: 0.92469\n",
      "[3,  1668] loss: 0.23232 correct: 0.92781\n",
      "[3,  1675] loss: 0.23406 correct: 0.92766\n",
      "[3,  1689] loss: 0.22840 correct: 0.93094\n",
      "[3,  1702] loss: 0.22242 correct: 0.93375\n",
      "[3,  1716] loss: 0.22790 correct: 0.93188\n",
      "[3,  1730] loss: 0.23267 correct: 0.93047\n",
      "[3,  1743] loss: 0.22936 correct: 0.93125\n",
      "[3,  1757] loss: 0.22868 correct: 0.93188\n",
      "[3,  1771] loss: 0.23704 correct: 0.92969\n",
      "[3,  1785] loss: 0.23721 correct: 0.92828\n",
      "[3,  1799] loss: 0.23620 correct: 0.92781\n",
      "[3,  1810] loss: 0.23764 correct: 0.92688\n",
      "[3,  1824] loss: 0.22931 correct: 0.92969\n",
      "[3,  1838] loss: 0.23366 correct: 0.92875\n",
      "[3,  1852] loss: 0.23721 correct: 0.92969\n",
      "[3,  1866] loss: 0.22315 correct: 0.93359\n",
      "[3,  1880] loss: 0.22750 correct: 0.93141\n",
      "[3,  1894] loss: 0.23207 correct: 0.93000\n",
      "[3,  1908] loss: 0.22242 correct: 0.93266\n",
      "[3,  1922] loss: 0.22072 correct: 0.93312\n",
      "[3,  1936] loss: 0.21016 correct: 0.93500\n",
      "[3,  1950] loss: 0.20867 correct: 0.93500\n",
      "[3,  1964] loss: 0.21947 correct: 0.93094\n",
      "[3,  1978] loss: 0.21731 correct: 0.93344\n",
      "[3,  1984] loss: 0.21679 correct: 0.93281\n",
      "[3,  1998] loss: 0.20479 correct: 0.93625\n",
      "[4,     1] loss: 0.21301 correct: 0.93406\n",
      "[4,    15] loss: 0.21722 correct: 0.93203\n",
      "[4,    29] loss: 0.21881 correct: 0.93125\n",
      "[4,    43] loss: 0.22515 correct: 0.92984\n",
      "[4,    57] loss: 0.22380 correct: 0.92875\n",
      "[4,    71] loss: 0.22704 correct: 0.92734\n",
      "[4,    85] loss: 0.22448 correct: 0.92906\n",
      "[4,    99] loss: 0.22227 correct: 0.92969\n",
      "[4,   110] loss: 0.21945 correct: 0.93156\n",
      "[4,   124] loss: 0.21700 correct: 0.93203\n",
      "[4,   138] loss: 0.21060 correct: 0.93547\n",
      "[4,   152] loss: 0.19695 correct: 0.93953\n",
      "[4,   166] loss: 0.19192 correct: 0.94141\n",
      "[4,   180] loss: 0.19380 correct: 0.94016\n",
      "[4,   194] loss: 0.19812 correct: 0.93812\n",
      "[4,   208] loss: 0.19769 correct: 0.93875\n",
      "[4,   222] loss: 0.19392 correct: 0.93875\n",
      "[4,   234] loss: 0.19422 correct: 0.93734\n",
      "[4,   238] loss: 0.19627 correct: 0.93672\n",
      "[4,   252] loss: 0.19580 correct: 0.93703\n",
      "[4,   266] loss: 0.18917 correct: 0.93797\n",
      "[4,   279] loss: 0.18930 correct: 0.93797\n",
      "[4,   293] loss: 0.18760 correct: 0.94031\n",
      "[4,   307] loss: 0.19759 correct: 0.93750\n",
      "[4,   321] loss: 0.19710 correct: 0.93797\n",
      "[4,   335] loss: 0.20222 correct: 0.93625\n",
      "[4,   349] loss: 0.20454 correct: 0.93625\n",
      "[4,   363] loss: 0.20907 correct: 0.93578\n",
      "[4,   377] loss: 0.21173 correct: 0.93375\n",
      "[4,   390] loss: 0.21065 correct: 0.93250\n",
      "[4,   404] loss: 0.20858 correct: 0.93344\n",
      "[4,   418] loss: 0.21103 correct: 0.93219\n",
      "[4,   432] loss: 0.21568 correct: 0.93188\n",
      "[4,   446] loss: 0.21729 correct: 0.93141\n",
      "[4,   460] loss: 0.21233 correct: 0.93297\n",
      "[4,   474] loss: 0.21754 correct: 0.93172\n",
      "[4,   488] loss: 0.21576 correct: 0.93281\n",
      "[4,   502] loss: 0.21295 correct: 0.93281\n",
      "[4,   516] loss: 0.20392 correct: 0.93641\n",
      "[4,   530] loss: 0.19394 correct: 0.93812\n",
      "[4,   543] loss: 0.19326 correct: 0.93891\n",
      "[4,   554] loss: 0.18944 correct: 0.94031\n",
      "[4,   568] loss: 0.19218 correct: 0.94094\n",
      "[4,   581] loss: 0.18996 correct: 0.94281\n",
      "[4,   595] loss: 0.18605 correct: 0.94453\n",
      "[4,   609] loss: 0.19354 correct: 0.94234\n",
      "[4,   623] loss: 0.19828 correct: 0.94125\n",
      "[4,   637] loss: 0.19662 correct: 0.94188\n",
      "[4,   651] loss: 0.20303 correct: 0.94016\n",
      "[4,   665] loss: 0.20389 correct: 0.93750\n",
      "[4,   679] loss: 0.20349 correct: 0.93563\n",
      "[4,   693] loss: 0.20559 correct: 0.93344\n",
      "[4,   707] loss: 0.20167 correct: 0.93375\n",
      "[4,   720] loss: 0.20966 correct: 0.93250\n",
      "[4,   734] loss: 0.22014 correct: 0.92891\n",
      "[4,   748] loss: 0.21778 correct: 0.93000\n",
      "[4,   762] loss: 0.21837 correct: 0.92953\n",
      "[4,   776] loss: 0.21943 correct: 0.92953\n",
      "[4,   790] loss: 0.21170 correct: 0.93203\n",
      "[4,   804] loss: 0.20634 correct: 0.93453\n",
      "[4,   818] loss: 0.19563 correct: 0.93781\n",
      "[4,   831] loss: 0.19245 correct: 0.93906\n",
      "[4,   845] loss: 0.18792 correct: 0.93875\n",
      "[4,   858] loss: 0.18954 correct: 0.94000\n",
      "[4,   872] loss: 0.18659 correct: 0.94063\n",
      "[4,   886] loss: 0.18957 correct: 0.94078\n",
      "[4,   900] loss: 0.19653 correct: 0.93969\n",
      "[4,   914] loss: 0.20733 correct: 0.93547\n",
      "[4,   928] loss: 0.20973 correct: 0.93406\n",
      "[4,   942] loss: 0.20867 correct: 0.93359\n",
      "[4,   956] loss: 0.20885 correct: 0.93328\n",
      "[4,   970] loss: 0.21103 correct: 0.93344\n",
      "[4,   984] loss: 0.21730 correct: 0.93063\n",
      "[4,   997] loss: 0.22092 correct: 0.92922\n",
      "[4,  1011] loss: 0.20612 correct: 0.93266\n",
      "[4,  1024] loss: 0.20072 correct: 0.93516\n",
      "[4,  1038] loss: 0.20829 correct: 0.93437\n",
      "[4,  1051] loss: 0.20417 correct: 0.93594\n",
      "[4,  1065] loss: 0.20610 correct: 0.93547\n",
      "[4,  1079] loss: 0.20327 correct: 0.93656\n",
      "[4,  1093] loss: 0.20611 correct: 0.93578\n",
      "[4,  1107] loss: 0.21122 correct: 0.93484\n",
      "[4,  1121] loss: 0.21387 correct: 0.93453\n",
      "[4,  1135] loss: 0.21381 correct: 0.93344\n",
      "[4,  1149] loss: 0.21431 correct: 0.93328\n",
      "[4,  1163] loss: 0.21109 correct: 0.93359\n",
      "[4,  1177] loss: 0.21562 correct: 0.93172\n",
      "[4,  1191] loss: 0.21593 correct: 0.93219\n",
      "[4,  1205] loss: 0.22160 correct: 0.92984\n",
      "[4,  1219] loss: 0.22359 correct: 0.92937\n",
      "[4,  1233] loss: 0.22387 correct: 0.93047\n",
      "[4,  1247] loss: 0.22831 correct: 0.93063\n",
      "[4,  1261] loss: 0.23180 correct: 0.93188\n",
      "[4,  1275] loss: 0.23458 correct: 0.93109\n",
      "[4,  1289] loss: 0.23431 correct: 0.93063\n",
      "[4,  1303] loss: 0.22941 correct: 0.93125\n",
      "[4,  1317] loss: 0.22873 correct: 0.93047\n",
      "[4,  1331] loss: 0.22328 correct: 0.93203\n",
      "[4,  1345] loss: 0.22452 correct: 0.92969\n",
      "[4,  1359] loss: 0.22971 correct: 0.92609\n",
      "[4,  1373] loss: 0.22055 correct: 0.92828\n",
      "[4,  1387] loss: 0.21793 correct: 0.93156\n",
      "[4,  1401] loss: 0.21212 correct: 0.93188\n",
      "[4,  1415] loss: 0.21213 correct: 0.93422\n",
      "[4,  1429] loss: 0.20430 correct: 0.93672\n",
      "[4,  1443] loss: 0.19879 correct: 0.93797\n",
      "[4,  1457] loss: 0.19519 correct: 0.93969\n",
      "[4,  1471] loss: 0.19990 correct: 0.93937\n",
      "[4,  1485] loss: 0.19311 correct: 0.93969\n",
      "[4,  1499] loss: 0.18893 correct: 0.94203\n",
      "[4,  1513] loss: 0.19449 correct: 0.94031\n",
      "[4,  1526] loss: 0.19422 correct: 0.93937\n",
      "[4,  1539] loss: 0.19814 correct: 0.93859\n",
      "[4,  1553] loss: 0.20061 correct: 0.93891\n",
      "[4,  1567] loss: 0.19679 correct: 0.94078\n",
      "[4,  1581] loss: 0.19983 correct: 0.94016\n",
      "[4,  1595] loss: 0.20448 correct: 0.93937\n",
      "[4,  1609] loss: 0.20596 correct: 0.93906\n",
      "[4,  1622] loss: 0.20024 correct: 0.94078\n",
      "[4,  1636] loss: 0.19928 correct: 0.94281\n",
      "[4,  1650] loss: 0.19869 correct: 0.94188\n",
      "[4,  1663] loss: 0.19657 correct: 0.94250\n",
      "[4,  1677] loss: 0.19883 correct: 0.94047\n",
      "[4,  1691] loss: 0.19125 correct: 0.94125\n",
      "[4,  1705] loss: 0.18152 correct: 0.94406\n",
      "[4,  1719] loss: 0.18822 correct: 0.94312\n",
      "[4,  1733] loss: 0.18499 correct: 0.94437\n",
      "[4,  1747] loss: 0.17147 correct: 0.94875\n",
      "[4,  1761] loss: 0.17056 correct: 0.94984\n",
      "[4,  1775] loss: 0.16443 correct: 0.95125\n",
      "[4,  1789] loss: 0.17172 correct: 0.94969\n",
      "[4,  1803] loss: 0.18149 correct: 0.94750\n",
      "[4,  1817] loss: 0.17452 correct: 0.94844\n",
      "[4,  1831] loss: 0.18084 correct: 0.94625\n",
      "[4,  1845] loss: 0.18966 correct: 0.94219\n",
      "[4,  1859] loss: 0.19908 correct: 0.94031\n",
      "[4,  1873] loss: 0.20094 correct: 0.94047\n",
      "[4,  1887] loss: 0.19872 correct: 0.94078\n",
      "[4,  1901] loss: 0.19455 correct: 0.94016\n",
      "[4,  1915] loss: 0.19478 correct: 0.94016\n",
      "[4,  1929] loss: 0.20062 correct: 0.93641\n",
      "[4,  1943] loss: 0.19860 correct: 0.93797\n",
      "[4,  1957] loss: 0.19826 correct: 0.93734\n",
      "[4,  1971] loss: 0.19429 correct: 0.93906\n",
      "[4,  1985] loss: 0.20131 correct: 0.93641\n",
      "[4,  1999] loss: 0.20011 correct: 0.93703\n",
      "[5,     1] loss: 0.20283 correct: 0.93672\n",
      "[5,    14] loss: 0.20195 correct: 0.93781\n",
      "[5,    28] loss: 0.19376 correct: 0.94188\n",
      "[5,    42] loss: 0.19773 correct: 0.93906\n",
      "[5,    56] loss: 0.19533 correct: 0.93969\n",
      "[5,    70] loss: 0.20268 correct: 0.93609\n",
      "[5,    84] loss: 0.19007 correct: 0.94094\n",
      "[5,    98] loss: 0.18823 correct: 0.94344\n",
      "[5,   112] loss: 0.17935 correct: 0.94594\n",
      "[5,   126] loss: 0.18031 correct: 0.94656\n",
      "[5,   140] loss: 0.17405 correct: 0.94969\n",
      "[5,   154] loss: 0.16324 correct: 0.95281\n",
      "[5,   168] loss: 0.15844 correct: 0.95500\n",
      "[5,   172] loss: 0.15379 correct: 0.95672\n",
      "[5,   186] loss: 0.15333 correct: 0.95609\n",
      "[5,   200] loss: 0.15477 correct: 0.95469\n",
      "[5,   214] loss: 0.16533 correct: 0.95109\n",
      "[5,   228] loss: 0.16842 correct: 0.94891\n",
      "[5,   242] loss: 0.16698 correct: 0.94750\n",
      "[5,   256] loss: 0.17681 correct: 0.94422\n",
      "[5,   270] loss: 0.17977 correct: 0.94266\n",
      "[5,   284] loss: 0.19146 correct: 0.93906\n",
      "[5,   298] loss: 0.19828 correct: 0.93781\n",
      "[5,   312] loss: 0.18909 correct: 0.94031\n",
      "[5,   326] loss: 0.18608 correct: 0.94094\n",
      "[5,   340] loss: 0.18732 correct: 0.94234\n",
      "[5,   354] loss: 0.19065 correct: 0.94281\n",
      "[5,   368] loss: 0.19376 correct: 0.94188\n",
      "[5,   382] loss: 0.19414 correct: 0.94109\n",
      "[5,   396] loss: 0.19192 correct: 0.94031\n",
      "[5,   410] loss: 0.19490 correct: 0.93984\n",
      "[5,   424] loss: 0.19572 correct: 0.93953\n",
      "[5,   438] loss: 0.19563 correct: 0.93937\n",
      "[5,   452] loss: 0.18659 correct: 0.94094\n",
      "[5,   466] loss: 0.18347 correct: 0.94156\n",
      "[5,   479] loss: 0.18103 correct: 0.94344\n",
      "[5,   493] loss: 0.18082 correct: 0.94422\n",
      "[5,   507] loss: 0.17144 correct: 0.94719\n",
      "[5,   521] loss: 0.16842 correct: 0.94812\n",
      "[5,   535] loss: 0.17082 correct: 0.94875\n",
      "[5,   549] loss: 0.17589 correct: 0.94563\n",
      "[5,   562] loss: 0.17453 correct: 0.94703\n",
      "[5,   575] loss: 0.17320 correct: 0.94766\n",
      "[5,   589] loss: 0.17201 correct: 0.94812\n",
      "[5,   603] loss: 0.17784 correct: 0.94547\n",
      "[5,   617] loss: 0.18343 correct: 0.94375\n",
      "[5,   631] loss: 0.18027 correct: 0.94266\n",
      "[5,   644] loss: 0.17488 correct: 0.94437\n",
      "[5,   658] loss: 0.18461 correct: 0.94281\n",
      "[5,   672] loss: 0.18123 correct: 0.94250\n",
      "[5,   686] loss: 0.17334 correct: 0.94469\n",
      "[5,   700] loss: 0.17358 correct: 0.94500\n",
      "[5,   714] loss: 0.17447 correct: 0.94484\n",
      "[5,   728] loss: 0.17339 correct: 0.94625\n",
      "[5,   742] loss: 0.17097 correct: 0.94781\n",
      "[5,   756] loss: 0.16446 correct: 0.94969\n",
      "[5,   769] loss: 0.16402 correct: 0.95000\n",
      "[5,   783] loss: 0.16803 correct: 0.94875\n",
      "[5,   797] loss: 0.16904 correct: 0.94766\n",
      "[5,   811] loss: 0.16522 correct: 0.94906\n",
      "[5,   825] loss: 0.16129 correct: 0.95031\n",
      "[5,   839] loss: 0.16244 correct: 0.95016\n",
      "[5,   853] loss: 0.16849 correct: 0.94656\n",
      "[5,   867] loss: 0.17518 correct: 0.94359\n",
      "[5,   880] loss: 0.17802 correct: 0.94203\n",
      "[5,   894] loss: 0.18529 correct: 0.94078\n",
      "[5,   908] loss: 0.18285 correct: 0.94000\n",
      "[5,   922] loss: 0.18374 correct: 0.93953\n",
      "[5,   936] loss: 0.18615 correct: 0.93906\n",
      "[5,   950] loss: 0.17392 correct: 0.94453\n",
      "[5,   964] loss: 0.17142 correct: 0.94625\n",
      "[5,   978] loss: 0.17072 correct: 0.94859\n",
      "[5,   992] loss: 0.16790 correct: 0.94984\n",
      "[5,  1006] loss: 0.16618 correct: 0.95047\n",
      "[5,  1020] loss: 0.16733 correct: 0.94953\n",
      "[5,  1034] loss: 0.16750 correct: 0.94937\n",
      "[5,  1048] loss: 0.17428 correct: 0.94594\n",
      "[5,  1062] loss: 0.17547 correct: 0.94453\n",
      "[5,  1076] loss: 0.17714 correct: 0.94344\n",
      "[5,  1090] loss: 0.17301 correct: 0.94563\n",
      "[5,  1104] loss: 0.16766 correct: 0.94734\n",
      "[5,  1118] loss: 0.16945 correct: 0.94734\n",
      "[5,  1132] loss: 0.17143 correct: 0.94641\n",
      "[5,  1146] loss: 0.17052 correct: 0.94703\n",
      "[5,  1159] loss: 0.16429 correct: 0.94969\n",
      "[5,  1173] loss: 0.16497 correct: 0.94859\n",
      "[5,  1187] loss: 0.16956 correct: 0.94719\n",
      "[5,  1201] loss: 0.17523 correct: 0.94484\n",
      "[5,  1215] loss: 0.17980 correct: 0.94359\n",
      "[5,  1229] loss: 0.18783 correct: 0.94078\n",
      "[5,  1243] loss: 0.18026 correct: 0.94453\n",
      "[5,  1257] loss: 0.18889 correct: 0.94141\n",
      "[5,  1271] loss: 0.19236 correct: 0.94188\n",
      "[5,  1285] loss: 0.18842 correct: 0.94250\n",
      "[5,  1299] loss: 0.18342 correct: 0.94406\n",
      "[5,  1313] loss: 0.18682 correct: 0.94203\n",
      "[5,  1327] loss: 0.17665 correct: 0.94641\n",
      "[5,  1341] loss: 0.17748 correct: 0.94469\n",
      "[5,  1355] loss: 0.17526 correct: 0.94578\n",
      "[5,  1369] loss: 0.17072 correct: 0.94641\n",
      "[5,  1383] loss: 0.17484 correct: 0.94469\n",
      "[5,  1397] loss: 0.16850 correct: 0.94609\n",
      "[5,  1411] loss: 0.16716 correct: 0.94797\n",
      "[5,  1425] loss: 0.16595 correct: 0.94859\n",
      "[5,  1439] loss: 0.16885 correct: 0.94688\n",
      "[5,  1453] loss: 0.16340 correct: 0.94906\n",
      "[5,  1467] loss: 0.15853 correct: 0.95094\n",
      "[5,  1481] loss: 0.15238 correct: 0.95281\n",
      "[5,  1495] loss: 0.15387 correct: 0.95375\n",
      "[5,  1508] loss: 0.15223 correct: 0.95422\n",
      "[5,  1522] loss: 0.14905 correct: 0.95516\n",
      "[5,  1536] loss: 0.14919 correct: 0.95609\n",
      "[5,  1550] loss: 0.15092 correct: 0.95469\n",
      "[5,  1564] loss: 0.15660 correct: 0.95266\n",
      "[5,  1578] loss: 0.15852 correct: 0.95109\n",
      "[5,  1592] loss: 0.15916 correct: 0.95109\n",
      "[5,  1606] loss: 0.16525 correct: 0.94922\n",
      "[5,  1620] loss: 0.16633 correct: 0.95016\n",
      "[5,  1634] loss: 0.16518 correct: 0.95016\n",
      "[5,  1648] loss: 0.18273 correct: 0.94703\n",
      "[5,  1662] loss: 0.18022 correct: 0.94891\n",
      "[5,  1676] loss: 0.18022 correct: 0.94906\n",
      "[5,  1690] loss: 0.17940 correct: 0.94953\n",
      "[5,  1704] loss: 0.18533 correct: 0.94812\n",
      "[5,  1718] loss: 0.18509 correct: 0.94609\n",
      "[5,  1732] loss: 0.18539 correct: 0.94437\n",
      "[5,  1746] loss: 0.17539 correct: 0.94547\n",
      "[5,  1760] loss: 0.17486 correct: 0.94359\n",
      "[5,  1774] loss: 0.17595 correct: 0.94297\n",
      "[5,  1788] loss: 0.18292 correct: 0.94125\n",
      "[5,  1802] loss: 0.17641 correct: 0.94234\n",
      "[5,  1816] loss: 0.17403 correct: 0.94266\n",
      "[5,  1830] loss: 0.16892 correct: 0.94578\n",
      "[5,  1843] loss: 0.16672 correct: 0.94703\n",
      "[5,  1857] loss: 0.16585 correct: 0.94781\n",
      "[5,  1870] loss: 0.17529 correct: 0.94609\n",
      "[5,  1884] loss: 0.17834 correct: 0.94563\n",
      "[5,  1898] loss: 0.17640 correct: 0.94734\n",
      "[5,  1911] loss: 0.18115 correct: 0.94578\n",
      "[5,  1923] loss: 0.18399 correct: 0.94437\n",
      "[5,  1937] loss: 0.18355 correct: 0.94375\n",
      "[5,  1951] loss: 0.18337 correct: 0.94563\n",
      "[5,  1965] loss: 0.17133 correct: 0.94922\n",
      "[5,  1979] loss: 0.16683 correct: 0.95016\n",
      "[5,  1991] loss: 0.16475 correct: 0.95047\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "losses, accuracies = deque(maxlen=100), deque(maxlen=100)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data, verbose in enumerate_report(trainloader, 5):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = outputs.cpu().detach().argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(labels.cpu().view_as(pred)).sum().item()\n",
    "        accuracy = correct / float(len(labels))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        if verbose and len(losses) > 5:\n",
    "            print('[%d, %5d] loss: %.5f correct: %.5f' % (epoch + 1, i + 1, np.mean(losses), np.mean(accuracies)))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
