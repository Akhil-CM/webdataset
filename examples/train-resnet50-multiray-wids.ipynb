{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-12 03:18:15,550\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List, Tuple, Dict, Optional, Any, Union, Callable, Iterable, Iterator, NamedTuple, Set, Sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import ray\n",
    "import wids\n",
    "import dataclasses\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "def enumerate_report(seq, delta, growth=1.0):\n",
    "    last = 0\n",
    "    count = 0\n",
    "    for count, item in enumerate(seq):\n",
    "        now = time.time()\n",
    "        if now - last > delta:\n",
    "            last = now\n",
    "            yield count, item, True\n",
    "        else:\n",
    "            yield count, item, False\n",
    "        delta *= growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not running in colab, caching data locally in ./_cache\n"
     ]
    }
   ],
   "source": [
    "bucket = \"https://storage.googleapis.com/webdataset/fake-imagenet\"\n",
    "trainset_url = bucket+\"/imagenet-train-{000000..001281}.tar\"\n",
    "valset_url = bucket+\"/imagenet-val-{000000..000049}.tar\"\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    cache_dir = None\n",
    "    print(\"running on colab, streaming data directly from storage\")\n",
    "else:\n",
    "    cache_dir = \"./_cache\"\n",
    "    print(f\"not running in colab, caching data locally in {cache_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gs://webdataset/fake-imagenet/imagenet-train.json base: gs://webdataset/fake-imagenet name: imagenet-train nfiles: 1282 nbytes: 31242280960 samples: 128200 cache: ./_cache\n",
      "/home/tmb/proj/webdataset/wids/wids.py:710: UserWarning: DistributedChunkedSampler is called without distributed initialized; assuming single process\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# This is a typical PyTorch dataset, except that we read from the cloud.\n",
    "\n",
    "def make_dataset_train():\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    def make_sample(sample):\n",
    "        image = sample[\".jpg\"]\n",
    "        label = sample[\".cls\"]\n",
    "        return transform_train(image), label\n",
    "\n",
    "    trainset = wids.ShardListDataset(\"gs://webdataset/fake-imagenet/imagenet-train.json\", cache_dir=\"./_cache\", keep=True)\n",
    "    trainset = trainset.add_transform(make_sample)\n",
    "\n",
    "    return trainset\n",
    "\n",
    "# To keep locality of reference in the dataloader, we use a special sampler\n",
    "# for distributed training, DistributedChunkedSampler.\n",
    "\n",
    "def make_dataloader_train():\n",
    "    dataset = make_dataset_train()\n",
    "    sampler = wids.DistributedChunkedSampler(dataset, chunksize=1000, shuffle=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, sampler=sampler, num_workers=4)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def make_dataloader(split=\"train\"):\n",
    "    \"\"\"Make a dataloader for training or validation.\"\"\"\n",
    "    if split == \"train\":\n",
    "        return make_dataloader_train()\n",
    "    elif split == \"val\":\n",
    "        return make_dataloader_val()\n",
    "    else:\n",
    "        raise ValueError(f\"unknown split {split}\")\n",
    "\n",
    "# Try it out.\n",
    "sample = next(iter(make_dataloader()))\n",
    "print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(rank=None, epochs=1, maxsteps=1000000000000000000, lr=0.001, momentum=0.9, world_size=2, backend='nccl', master_addr='localhost', master_port='12355', report_s=15.0, report_growth=1.1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For convenience, we collect all the configuration parameters into\n",
    "# a dataclass.\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Config:\n",
    "    rank: Optional[int] = None\n",
    "    epochs: int = 1\n",
    "    maxsteps: int = int(1e18)\n",
    "    lr: float = 0.001\n",
    "    momentum: float = 0.9\n",
    "    world_size: int = 2\n",
    "    backend: str = \"nccl\"\n",
    "    master_addr: str = \"localhost\"\n",
    "    master_port: str = \"12355\"\n",
    "    report_s: float = 15.0\n",
    "    report_growth: float = 1.1\n",
    "\n",
    "Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A typical PyTorch training function.\n",
    "\n",
    "def train(config):\n",
    "    # Define the model, loss function, and optimizer\n",
    "    model = resnet50(pretrained=False).cuda()\n",
    "    if config.rank is not None:\n",
    "        model = DistributedDataParallel(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config.lr)\n",
    "\n",
    "    # Data loading code\n",
    "    trainloader = make_dataloader(split='train')\n",
    "\n",
    "    losses, accuracies, steps = deque(maxlen=100), deque(maxlen=100), 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(config.epochs):\n",
    "        for i, data, verbose in enumerate_report(trainloader, config.report_s):\n",
    "            inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # just bookkeping and progress report\n",
    "            steps += len(labels)\n",
    "            accuracy = (outputs.argmax(1) == labels).float().mean()  # calculate accuracy\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(accuracy.item())\n",
    "            if verbose and len(losses) > 0:\n",
    "                avgloss = sum(losses)/len(losses)\n",
    "                avgaccuracy = sum(accuracies)/len(accuracies)\n",
    "                print(f\"rank {config.rank} epoch {epoch:5d}/{i:9d} loss {avgloss:8.3f} acc {avgaccuracy:8.3f} {steps:9d}\", file=sys.stderr)\n",
    "            if steps > config.maxsteps:\n",
    "                print(\"finished training (maxsteps)\", steps, config.maxsteps, file=sys.stderr)\n",
    "                return\n",
    "\n",
    "    print(\"finished Training\", steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "gs://webdataset/fake-imagenet/imagenet-train.json base: gs://webdataset/fake-imagenet name: imagenet-train nfiles: 1282 nbytes: 31242280960 samples: 128200 cache: ./_cache\n",
      "rank None epoch     0/        0 loss    7.180 acc    0.000        32\n",
      "finished training (maxsteps) 1024 1000\n"
     ]
    }
   ],
   "source": [
    "# A quick smoke test.\n",
    "\n",
    "config = Config()\n",
    "config.epochs = 1\n",
    "config.maxsteps = 1000\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distributed training function to be used with Ray.\n",
    "# Since this is started via Ray remote, we set up the distributed\n",
    "# training environment here.\n",
    "\n",
    "def train_in_ray(rank, config):\n",
    "    # Set up distributed PyTorch.\n",
    "    if rank is not None:\n",
    "        config.rank = rank\n",
    "        os.environ['MASTER_ADDR'] = config.master_addr\n",
    "        os.environ['MASTER_PORT'] = config.master_port\n",
    "        print(f\"rank {rank} initializing process group\", file=sys.stderr)\n",
    "        dist.init_process_group(backend=config.backend, rank=rank, world_size=config.world_size)\n",
    "        print(f\"rank {rank} done initializing process group\", file=sys.stderr)\n",
    "    train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#gpus available in the cluster 2.0\n",
      "[{'NodeID': '1548755e0d56fbbaea367df3cb590eeb6af479d17a2f1c9b48a2e8a4', 'Alive': True, 'NodeManagerAddress': '10.20.13.236', 'NodeManagerHostname': 'bragi', 'NodeManagerPort': 42255, 'ObjectManagerPort': 38851, 'ObjectStoreSocketName': '/tmp/ray/session_2023-12-12_03-18-27_260854_2295938/sockets/plasma_store', 'RayletSocketName': '/tmp/ray/session_2023-12-12_03-18-27_260854_2295938/sockets/raylet', 'MetricsExportPort': 63404, 'NodeName': '10.20.13.236', 'RuntimeEnvAgentPort': 42330, 'alive': True, 'Resources': {'GPU': 2.0, 'CPU': 12.0, 'accelerator_type:TITAN': 1.0, 'memory': 17423568078.0, 'node:10.20.13.236': 1.0, 'node:__internal_head__': 1.0, 'object_store_memory': 8711784038.0}, 'Labels': {'ray.io/node_id': '1548755e0d56fbbaea367df3cb590eeb6af479d17a2f1c9b48a2e8a4'}}]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Ray cluster if it hasn't been initialized yet.\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init()\n",
    "print(\"#gpus available in the cluster\", ray.available_resources()['GPU'])\n",
    "print(ray.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 initializing process group\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 done initializing process group\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m /home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m /home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m gs://webdataset/fake-imagenet/imagenet-train.json base: gs://webdataset/fake-imagenet name: imagenet-train nfiles: 1282 nbytes: 31242280960 samples: 128200 cache: ./_cache\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/        0 loss    7.045 acc    0.000        32\n",
      "\u001b[36m(train_remote pid=2301259)\u001b[0m rank 1 initializing process group\n",
      "\u001b[36m(train_remote pid=2301259)\u001b[0m rank 1 done initializing process group\n",
      "\u001b[36m(train_remote pid=2301259)\u001b[0m /home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\u001b[36m(train_remote pid=2301259)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_remote pid=2301259)\u001b[0m /home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "\u001b[36m(train_remote pid=2301259)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[36m(train_remote pid=2301259)\u001b[0m gs://webdataset/fake-imagenet/imagenet-train.json base: gs://webdataset/fake-imagenet name: imagenet-train nfiles: 1282 nbytes: 31242280960 samples: 128200 cache: ./_cache\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/       21 loss    6.116 acc    0.048       704\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/       43 loss    5.348 acc    0.059      1408\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/       65 loss    4.817 acc    0.060      2112\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/       87 loss    4.445 acc    0.064      2816\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      109 loss    3.942 acc    0.076      3520\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      131 loss    3.447 acc    0.083      4224\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      153 loss    3.208 acc    0.090      4928\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      175 loss    3.092 acc    0.093      5632\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      197 loss    3.034 acc    0.094      6336\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      219 loss    2.992 acc    0.096      7040\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      241 loss    2.957 acc    0.102      7744\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      263 loss    2.935 acc    0.107      8448\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      285 loss    2.911 acc    0.115      9152\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      307 loss    2.888 acc    0.118      9856\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      329 loss    2.874 acc    0.114     10560\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      351 loss    2.852 acc    0.115     11264\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      373 loss    2.839 acc    0.109     11968\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      395 loss    2.828 acc    0.105     12672\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2301260)\u001b[0m rank 0 epoch     0/      417 loss    2.827 acc    0.109     13376\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "def train_remote(rank, args):\n",
    "    # Ray will automatically set CUDA_VISIBLE_DEVICES for each task.\n",
    "    train_in_ray(rank, args)\n",
    "\n",
    "def distributed_training(world_size=2):\n",
    "    args = Config()\n",
    "    num_gpus = ray.available_resources()['GPU']\n",
    "    args.world_size = min(world_size, num_gpus)\n",
    "    results = ray.get([train_remote.remote(i, args) for i in range(args.world_size)])\n",
    "    print(results)\n",
    "\n",
    "distributed_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
