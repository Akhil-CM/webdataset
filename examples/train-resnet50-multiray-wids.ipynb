{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import ray\n",
    "import wids\n",
    "import dataclasses\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "def enumerate_report(seq, delta, growth=1.0):\n",
    "    last = 0\n",
    "    count = 0\n",
    "    for count, item in enumerate(seq):\n",
    "        now = time.time()\n",
    "        if now - last > delta:\n",
    "            last = now\n",
    "            yield count, item, True\n",
    "        else:\n",
    "            yield count, item, False\n",
    "        delta *= growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not running in colab, caching data locally in ./_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gs://webdataset/fake-imagenet/imagenet-train.json base: gs://webdataset/fake-imagenet name: imagenet-train nfiles: 1282 nbytes: 31242280960 samples: 128200 cache: ./_cache\n",
      "/home/tmb/proj/webdataset/wids/wids.py:710: UserWarning: DistributedChunkedSampler is called without distributed initialized; assuming single process\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "bucket = \"https://storage.googleapis.com/webdataset/fake-imagenet\"\n",
    "trainset_url = bucket+\"/imagenet-train-{000000..001281}.tar\"\n",
    "valset_url = bucket+\"/imagenet-val-{000000..000049}.tar\"\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    cache_dir = None\n",
    "    print(\"running on colab, streaming data directly from storage\")\n",
    "else:\n",
    "    cache_dir = \"./_cache\"\n",
    "    print(f\"not running in colab, caching data locally in {cache_dir}\")\n",
    "\n",
    "def make_dataset_train():\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    def make_sample(sample):\n",
    "        image = sample[\".jpg\"]\n",
    "        label = sample[\".cls\"]\n",
    "        return transform_train(image), label\n",
    "\n",
    "    trainset = wids.ShardListDataset(\"gs://webdataset/fake-imagenet/imagenet-train.json\", cache_dir=\"./_cache\", keep=True)\n",
    "    trainset = trainset.add_transform(make_sample)\n",
    "\n",
    "    return trainset\n",
    "\n",
    "\n",
    "def make_dataloader_train():\n",
    "    dataset = make_dataset_train()\n",
    "    sampler = wids.DistributedChunkedSampler(dataset, chunksize=1000, shuffle=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, sampler=sampler, num_workers=4)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def make_dataloader(split=\"train\"):\n",
    "    \"\"\"Make a dataloader for training or validation.\"\"\"\n",
    "    if split == \"train\":\n",
    "        return make_dataloader_train()\n",
    "    elif split == \"val\":\n",
    "        return make_dataloader_val()\n",
    "    else:\n",
    "        raise ValueError(f\"unknown split {split}\")\n",
    "\n",
    "# Try it out.\n",
    "sample = next(iter(make_dataloader()))\n",
    "print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Args:\n",
    "    epochs: int = 1\n",
    "    maxsteps: int = int(1e18)\n",
    "    lr: float = 0.001\n",
    "    momentum: float = 0.9\n",
    "    rank: int = 0\n",
    "    world_size: int = 2\n",
    "    backend: str = \"nccl\"\n",
    "    master_addr: str = \"localhost\"\n",
    "    master_port: str = \"12355\"\n",
    "    report_s: float = 15.0\n",
    "    report_growth: float = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rank, args):\n",
    "    # Set up distributed PyTorch.\n",
    "    if rank is not None:\n",
    "        os.environ['MASTER_ADDR'] = args.master_addr\n",
    "        os.environ['MASTER_PORT'] = args.master_port\n",
    "        print(f\"rank {rank} initializing process group\", file=sys.stderr)\n",
    "        dist.init_process_group(backend=args.backend, rank=rank, world_size=args.world_size)\n",
    "        print(f\"rank {rank} done initializing process group\", file=sys.stderr)\n",
    "\n",
    "    # Define the model, loss function, and optimizer\n",
    "    model = resnet50(pretrained=False).cuda()\n",
    "    if rank is not None:\n",
    "        model = DistributedDataParallel(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Data loading code\n",
    "    trainloader = make_dataloader(split='train')\n",
    "\n",
    "    losses, accuracies, steps = deque(maxlen=100), deque(maxlen=100), 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(args.epochs):\n",
    "        for i, data, verbose in enumerate_report(trainloader, args.report_s):\n",
    "            inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # update statistics\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            accuracy = (outputs.argmax(1) == labels).float().mean()  # calculate accuracy\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(accuracy.item())\n",
    "\n",
    "            if verbose and len(losses) > 0:\n",
    "                avgloss = sum(losses)/len(losses)\n",
    "                avgaccuracy = sum(accuracies)/len(accuracies)\n",
    "                print(f\"rank {rank} epoch {epoch:5d}/{i:9d} loss {avgloss:8.3f} acc {avgaccuracy:8.3f} {steps:9d}\", file=sys.stderr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            steps += len(labels)\n",
    "            if steps > args.maxsteps:\n",
    "                print(\"finished training (maxsteps)\", steps, args.maxsteps, file=sys.stderr)\n",
    "                return\n",
    "\n",
    "    print(\"finished Training\", steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "args = Args()\n",
    "args.epochs = 1\n",
    "args.maxsteps = 100000\n",
    "train(None, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 02:32:13,935\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not ray.is_initialized():\n",
    "    ray.init()\n",
    "ray.available_resources()['GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 initializing process group\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 done initializing process group\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m /home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m /home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m gs://webdataset/fake-imagenet/imagenet-train.json base: gs://webdataset/fake-imagenet name: imagenet-train nfiles: 1282 nbytes: 31242280960 samples: 128200 cache: ./_cache\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 initializing process group\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 done initializing process group\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m /home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m /home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/        0 loss    6.811 acc    0.000         0\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m gs://webdataset/fake-imagenet/imagenet-train.json base: gs://webdataset/fake-imagenet name: imagenet-train nfiles: 1282 nbytes: 31242280960 samples: 128200 cache: ./_cache\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/        0 loss    6.931 acc    0.000         0\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/        2 loss    6.704 acc    0.021        64\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/       21 loss    5.931 acc    0.033       672\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/       25 loss    5.721 acc    0.052       800\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/       31 loss    5.522 acc    0.040       992\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/       35 loss    5.364 acc    0.053      1120\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/       55 loss    4.824 acc    0.049      1760\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/       58 loss    4.749 acc    0.060      1856\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/       62 loss    4.680 acc    0.047      1984\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/       64 loss    4.632 acc    0.059      2048\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/       86 loss    4.302 acc    0.051      2752\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/       87 loss    4.286 acc    0.061      2784\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/       93 loss    4.219 acc    0.052      2976\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/       95 loss    4.193 acc    0.063      3040\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      116 loss    3.641 acc    0.061      3712\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      117 loss    3.622 acc    0.072      3744\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      125 loss    3.459 acc    0.066      4000\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      127 loss    3.431 acc    0.076      4064\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      149 loss    3.192 acc    0.077      4768\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      150 loss    3.189 acc    0.081      4800\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      156 loss    3.149 acc    0.081      4992\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      158 loss    3.139 acc    0.082      5056\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      180 loss    3.048 acc    0.090      5760\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      181 loss    3.045 acc    0.088      5792\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      187 loss    3.025 acc    0.092      5984\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      189 loss    3.021 acc    0.092      6048\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      210 loss    2.979 acc    0.098      6720\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      211 loss    2.978 acc    0.092      6752\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      218 loss    2.965 acc    0.101      6976\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      220 loss    2.961 acc    0.093      7040\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      242 loss    2.940 acc    0.100      7744\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      243 loss    2.929 acc    0.103      7776\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      250 loss    2.930 acc    0.100      8000\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      252 loss    2.922 acc    0.105      8064\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      274 loss    2.910 acc    0.108      8768\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      275 loss    2.903 acc    0.108      8800\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      281 loss    2.898 acc    0.113      8992\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      283 loss    2.892 acc    0.113      9056\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      305 loss    2.877 acc    0.111      9760\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      306 loss    2.871 acc    0.121      9792\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      312 loss    2.870 acc    0.112      9984\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      314 loss    2.868 acc    0.119     10048\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      336 loss    2.859 acc    0.109     10752\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      337 loss    2.857 acc    0.114     10784\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      343 loss    2.854 acc    0.110     10976\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      345 loss    2.851 acc    0.111     11040\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      367 loss    2.842 acc    0.107     11744\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      368 loss    2.840 acc    0.106     11776\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      375 loss    2.838 acc    0.104     12000\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      377 loss    2.836 acc    0.107     12064\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      399 loss    2.830 acc    0.106     12768\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      400 loss    2.825 acc    0.106     12800\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      406 loss    2.827 acc    0.107     12992\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      408 loss    2.825 acc    0.106     13056\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      430 loss    2.817 acc    0.104     13760\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      431 loss    2.824 acc    0.113     13792\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      437 loss    2.816 acc    0.105     13984\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      439 loss    2.820 acc    0.111     14048\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      461 loss    2.800 acc    0.116     14752\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      462 loss    2.819 acc    0.113     14784\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      468 loss    2.796 acc    0.114     14976\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      470 loss    2.815 acc    0.114     15040\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      492 loss    2.797 acc    0.120     15744\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      493 loss    2.806 acc    0.117     15776\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      500 loss    2.799 acc    0.119     16000\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      502 loss    2.800 acc    0.118     16064\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      524 loss    2.789 acc    0.124     16768\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      525 loss    2.782 acc    0.129     16800\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      536 loss    2.786 acc    0.127     17152\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      537 loss    2.782 acc    0.131     17184\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      559 loss    2.786 acc    0.123     17888\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      560 loss    2.768 acc    0.136     17920\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      564 loss    2.784 acc    0.125     18048\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      565 loss    2.766 acc    0.139     18080\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      587 loss    2.770 acc    0.124     18784\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      588 loss    2.770 acc    0.135     18816\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      596 loss    2.771 acc    0.127     19072\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      597 loss    2.763 acc    0.140     19104\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      619 loss    2.763 acc    0.131     19808\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      620 loss    2.763 acc    0.133     19840\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      625 loss    2.763 acc    0.131     20000\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      626 loss    2.764 acc    0.130     20032\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      648 loss    2.766 acc    0.124     20736\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      649 loss    2.757 acc    0.129     20768\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      658 loss    2.759 acc    0.131     21056\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      659 loss    2.754 acc    0.133     21088\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      681 loss    2.759 acc    0.131     21792\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      682 loss    2.750 acc    0.137     21824\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      690 loss    2.754 acc    0.136     22080\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      691 loss    2.752 acc    0.135     22112\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      713 loss    2.749 acc    0.139     22816\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      714 loss    2.754 acc    0.133     22848\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      719 loss    2.746 acc    0.143     23008\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      719 loss    2.745 acc    0.135     23008\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      742 loss    2.746 acc    0.144     23744\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      743 loss    2.733 acc    0.142     23776\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      753 loss    2.745 acc    0.144     24096\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      754 loss    2.728 acc    0.146     24128\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      776 loss    2.746 acc    0.146     24832\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      777 loss    2.713 acc    0.149     24864\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      781 loss    2.739 acc    0.149     24992\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      781 loss    2.713 acc    0.149     24992\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      803 loss    2.728 acc    0.153     25696\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      805 loss    2.706 acc    0.152     25760\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      818 loss    2.730 acc    0.150     26176\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      820 loss    2.705 acc    0.153     26240\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      841 loss    2.715 acc    0.158     26912\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      843 loss    2.709 acc    0.151     26976\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      847 loss    2.713 acc    0.160     27104\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      862 loss    2.704 acc    0.152     27584\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      870 loss    2.698 acc    0.166     27840\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      875 loss    2.708 acc    0.152     28000\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      898 loss    2.702 acc    0.155     28736\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      910 loss    2.706 acc    0.153     29120\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      933 loss    2.700 acc    0.163     29856\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      937 loss    2.672 acc    0.177     29984\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      941 loss    2.691 acc    0.163     30112\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      957 loss    2.669 acc    0.180     30624\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      964 loss    2.685 acc    0.167     30848\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      969 loss    2.663 acc    0.182     31008\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      974 loss    2.681 acc    0.164     31168\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/      992 loss    2.686 acc    0.175     31744\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/      997 loss    2.677 acc    0.164     31904\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1000 loss    2.680 acc    0.175     32000\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1001 loss    2.676 acc    0.166     32032\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1023 loss    2.680 acc    0.176     32736\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1024 loss    2.683 acc    0.163     32768\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1031 loss    2.684 acc    0.171     32992\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1031 loss    2.681 acc    0.161     32992\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1053 loss    2.691 acc    0.168     33696\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1055 loss    2.682 acc    0.156     33760\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1064 loss    2.688 acc    0.169     34048\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1066 loss    2.677 acc    0.160     34112\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1087 loss    2.676 acc    0.170     34784\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1089 loss    2.671 acc    0.164     34848\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1095 loss    2.674 acc    0.171     35040\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1095 loss    2.667 acc    0.165     35040\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1118 loss    2.666 acc    0.179     35776\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1118 loss    2.661 acc    0.170     35776\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1130 loss    2.666 acc    0.178     36160\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1130 loss    2.663 acc    0.177     36160\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1153 loss    2.649 acc    0.182     36896\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1153 loss    2.647 acc    0.182     36896\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1159 loss    2.646 acc    0.185     37088\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1159 loss    2.651 acc    0.181     37088\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1182 loss    2.644 acc    0.180     37824\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1182 loss    2.647 acc    0.186     37824\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1193 loss    2.636 acc    0.189     38176\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1193 loss    2.639 acc    0.193     38176\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1216 loss    2.636 acc    0.196     38912\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1216 loss    2.639 acc    0.187     38912\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1226 loss    2.638 acc    0.184     39232\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1226 loss    2.632 acc    0.199     39232\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1249 loss    2.642 acc    0.188     39968\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1249 loss    2.644 acc    0.196     39968\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1259 loss    2.646 acc    0.189     40288\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1259 loss    2.640 acc    0.198     40288\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1281 loss    2.638 acc    0.199     40992\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1281 loss    2.642 acc    0.191     40992\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1304 loss    2.632 acc    0.198     41728\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1304 loss    2.639 acc    0.183     41728\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1317 loss    2.624 acc    0.196     42144\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1317 loss    2.626 acc    0.186     42144\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1340 loss    2.627 acc    0.196     42880\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1340 loss    2.620 acc    0.192     42880\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1348 loss    2.621 acc    0.195     43136\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1348 loss    2.606 acc    0.197     43136\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1371 loss    2.622 acc    0.187     43872\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1371 loss    2.596 acc    0.204     43872\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1381 loss    2.615 acc    0.184     44192\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1381 loss    2.591 acc    0.207     44192\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1404 loss    2.611 acc    0.188     44928\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1404 loss    2.580 acc    0.210     44928\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1414 loss    2.609 acc    0.192     45248\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1414 loss    2.579 acc    0.211     45248\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1437 loss    2.602 acc    0.197     45984\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1437 loss    2.573 acc    0.206     45984\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1457 loss    2.578 acc    0.207     46624\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1460 loss    2.592 acc    0.209     46720\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1468 loss    2.580 acc    0.207     46976\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1470 loss    2.583 acc    0.216     47040\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1492 loss    2.582 acc    0.212     47744\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1493 loss    2.578 acc    0.217     47776\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1502 loss    2.577 acc    0.214     48064\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1503 loss    2.570 acc    0.219     48096\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1525 loss    2.573 acc    0.221     48800\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1526 loss    2.563 acc    0.226     48832\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1533 loss    2.570 acc    0.220     49056\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1534 loss    2.566 acc    0.225     49088\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1556 loss    2.572 acc    0.215     49792\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1557 loss    2.564 acc    0.227     49824\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1564 loss    2.571 acc    0.215     50048\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1565 loss    2.565 acc    0.225     50080\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1587 loss    2.573 acc    0.207     50784\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1588 loss    2.571 acc    0.223     50816\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1593 loss    2.573 acc    0.223     50976\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1593 loss    2.570 acc    0.207     50976\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1615 loss    2.576 acc    0.220     51680\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1616 loss    2.578 acc    0.207     51712\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1629 loss    2.574 acc    0.213     52128\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1630 loss    2.581 acc    0.199     52160\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1652 loss    2.562 acc    0.217     52864\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1653 loss    2.572 acc    0.206     52896\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1664 loss    2.567 acc    0.216     53248\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1665 loss    2.569 acc    0.211     53280\n",
      "\u001b[36m(train_remote pid=2094790)\u001b[0m rank 0 epoch     0/     1687 loss    2.560 acc    0.218     53984\n",
      "\u001b[36m(train_remote pid=2094789)\u001b[0m rank 1 epoch     0/     1687 loss    2.572 acc    0.217     53984\n"
     ]
    }
   ],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "def train_remote(rank, args):\n",
    "    # Ray will automatically set CUDA_VISIBLE_DEVICES for each task.\n",
    "    train(rank, args)\n",
    "\n",
    "def distributed_training(world_size=2):\n",
    "    args = Args()\n",
    "    num_gpus = ray.available_resources()['GPU']\n",
    "    args.world_size = min(world_size, num_gpus)\n",
    "    results = ray.get([train_remote.remote(i, args) for i in range(args.world_size)])\n",
    "    print(results)\n",
    "\n",
    "distributed_training(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
