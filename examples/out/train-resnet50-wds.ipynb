{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56df52e4",
   "metadata": {
    "papermill": {
     "duration": 0.00392,
     "end_time": "2023-12-17T04:03:25.601350",
     "exception": false,
     "start_time": "2023-12-17T04:03:25.597430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Resnet 50 Training on (Fake)Imagenet with WebDataset\n",
    "\n",
    "This notebook illustrates how to use WebDataset with PyTorch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaa1989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:25.610018Z",
     "iopub.status.busy": "2023-12-17T04:03:25.609699Z",
     "iopub.status.idle": "2023-12-17T04:03:27.830358Z",
     "shell.execute_reply": "2023-12-17T04:03:27.829588Z"
    },
    "papermill": {
     "duration": 2.228496,
     "end_time": "2023-12-17T04:03:27.833614",
     "exception": false,
     "start_time": "2023-12-17T04:03:25.605118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "\n",
    "# helpers\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def enumerate_report(seq, delta, growth=1.0):\n",
    "    last = 0\n",
    "    count = 0\n",
    "    for count, item in enumerate(seq):\n",
    "        now = time.time()\n",
    "        if now - last > delta:\n",
    "            last = now\n",
    "            yield count, item, True\n",
    "        else:\n",
    "            yield count, item, False\n",
    "        delta *= growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48af4cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:27.846764Z",
     "iopub.status.busy": "2023-12-17T04:03:27.846488Z",
     "iopub.status.idle": "2023-12-17T04:03:27.855374Z",
     "shell.execute_reply": "2023-12-17T04:03:27.854800Z"
    },
    "papermill": {
     "duration": 0.018578,
     "end_time": "2023-12-17T04:03:27.858301",
     "exception": false,
     "start_time": "2023-12-17T04:03:27.839723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We usually abbreviate webdataset as wds\n",
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5fcb22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:27.870420Z",
     "iopub.status.busy": "2023-12-17T04:03:27.870205Z",
     "iopub.status.idle": "2023-12-17T04:03:27.873752Z",
     "shell.execute_reply": "2023-12-17T04:03:27.873188Z"
    },
    "papermill": {
     "duration": 0.013361,
     "end_time": "2023-12-17T04:03:27.877148",
     "exception": false,
     "start_time": "2023-12-17T04:03:27.863787",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "epochs = 1\n",
    "max_steps = int(1e12)\n",
    "batchsize = 32\n",
    "bucket = \"https://storage.googleapis.com/webdataset/fake-imagenet\"\n",
    "training_urls = bucket + \"/imagenet-train-{000000..001281}.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c450c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:27.889900Z",
     "iopub.status.busy": "2023-12-17T04:03:27.889566Z",
     "iopub.status.idle": "2023-12-17T04:03:27.893699Z",
     "shell.execute_reply": "2023-12-17T04:03:27.892720Z"
    },
    "papermill": {
     "duration": 0.012449,
     "end_time": "2023-12-17T04:03:27.895435",
     "exception": false,
     "start_time": "2023-12-17T04:03:27.882986",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_steps = 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a999f5",
   "metadata": {
    "papermill": {
     "duration": 0.002338,
     "end_time": "2023-12-17T04:03:27.900117",
     "exception": false,
     "start_time": "2023-12-17T04:03:27.897779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loader Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b3ec6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:27.906097Z",
     "iopub.status.busy": "2023-12-17T04:03:27.905795Z",
     "iopub.status.idle": "2023-12-17T04:03:28.040016Z",
     "shell.execute_reply": "2023-12-17T04:03:28.038113Z"
    },
    "papermill": {
     "duration": 0.141371,
     "end_time": "2023-12-17T04:03:28.043839",
     "exception": false,
     "start_time": "2023-12-17T04:03:27.902468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not running in colab, caching data locally in ./_cache\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# WebDataset is designed to work without any local storage. Use caching\n",
    "# only if you are on a desktop with slow networking.\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    cache_dir = None\n",
    "    print(\"running on colab, streaming data directly from storage\")\n",
    "else:\n",
    "    !mkdir -p ./_cache\n",
    "    cache_dir = \"./_cache\"\n",
    "    print(f\"not running in colab, caching data locally in {cache_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2f8609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:28.059230Z",
     "iopub.status.busy": "2023-12-17T04:03:28.058656Z",
     "iopub.status.idle": "2023-12-17T04:03:28.076033Z",
     "shell.execute_reply": "2023-12-17T04:03:28.074372Z"
    },
    "papermill": {
     "duration": 0.02922,
     "end_time": "2023-12-17T04:03:28.079724",
     "exception": false,
     "start_time": "2023-12-17T04:03:28.050504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The standard TorchVision transformations.\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def make_sample(sample, val=False):\n",
    "    \"\"\"Take a decoded sample dictionary, augment it, and return an (image, label) tuple.\"\"\"\n",
    "    assert not val, \"only implemented training dataset for this notebook\"\n",
    "    image = sample[\"jpg\"]\n",
    "    label = sample[\"cls\"]\n",
    "    return transform_train(image), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c9c2a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:28.093887Z",
     "iopub.status.busy": "2023-12-17T04:03:28.093349Z",
     "iopub.status.idle": "2023-12-17T04:03:28.113199Z",
     "shell.execute_reply": "2023-12-17T04:03:28.111350Z"
    },
    "papermill": {
     "duration": 0.031521,
     "end_time": "2023-12-17T04:03:28.117059",
     "exception": false,
     "start_time": "2023-12-17T04:03:28.085538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the datasets with shard and sample shuffling and decoding.\n",
    "trainset = wds.WebDataset(\n",
    "    training_urls, resampled=True, cache_dir=cache_dir, shardshuffle=True\n",
    ")\n",
    "trainset = trainset.shuffle(1000).decode(\"pil\").map(make_sample)\n",
    "\n",
    "# Since this is an IterableDataset, PyTorch requires that we batch in the dataset.\n",
    "# WebLoader is PyTorch DataLoader with some convenience methods.\n",
    "trainset = trainset.batched(64)\n",
    "trainloader = wds.WebLoader(trainset, batch_size=None, num_workers=4)\n",
    "\n",
    "# Unbatch, shuffle between workers, then rebatch.\n",
    "trainloader = trainloader.unbatched().shuffle(1000).batched(64)\n",
    "\n",
    "# Since we are using resampling, the dataset is infinite; set an artificial epoch size.\n",
    "trainloader = trainloader.with_epoch(1282 * 100 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b835febb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:28.131434Z",
     "iopub.status.busy": "2023-12-17T04:03:28.130728Z",
     "iopub.status.idle": "2023-12-17T04:03:29.309641Z",
     "shell.execute_reply": "2023-12-17T04:03:29.308981Z"
    },
    "papermill": {
     "duration": 1.188879,
     "end_time": "2023-12-17T04:03:29.311754",
     "exception": false,
     "start_time": "2023-12-17T04:03:28.122875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Smoke test it.\n",
    "\n",
    "os.environ[\"GOPEN_VERBOSE\"] = \"1\"\n",
    "images, classes = next(iter(trainloader))\n",
    "print(images.shape, classes.shape)\n",
    "os.environ[\"GOPEN_VERBOSE\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe039eed",
   "metadata": {
    "papermill": {
     "duration": 0.003985,
     "end_time": "2023-12-17T04:03:29.320382",
     "exception": false,
     "start_time": "2023-12-17T04:03:29.316397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch Training\n",
    "\n",
    "This is a typical PyTorch training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bea28f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:29.330567Z",
     "iopub.status.busy": "2023-12-17T04:03:29.330121Z",
     "iopub.status.idle": "2023-12-17T04:03:31.448494Z",
     "shell.execute_reply": "2023-12-17T04:03:31.447512Z"
    },
    "papermill": {
     "duration": 2.127323,
     "end_time": "2023-12-17T04:03:31.451679",
     "exception": false,
     "start_time": "2023-12-17T04:03:29.324356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# The usual PyTorch model definition. We use an uninitialized ResNet50 model.\n",
    "\n",
    "model = resnet50(pretrained=False)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dacbad89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T04:03:31.466218Z",
     "iopub.status.busy": "2023-12-17T04:03:31.466014Z",
     "iopub.status.idle": "2023-12-17T04:04:33.970543Z",
     "shell.execute_reply": "2023-12-17T04:04:33.969905Z"
    },
    "papermill": {
     "duration": 62.514654,
     "end_time": "2023-12-17T04:04:33.973469",
     "exception": false,
     "start_time": "2023-12-17T04:03:31.458815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 4.85199 correct: 0.05937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    24] loss: 4.32780 correct: 0.07422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    38] loss: 4.07419 correct: 0.08347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    52] loss: 3.78309 correct: 0.09856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    66] loss: 3.54982 correct: 0.12311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    80] loss: 3.35860 correct: 0.15176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    94] loss: 3.19739 correct: 0.17803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   108] loss: 2.92974 correct: 0.21313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   122] loss: 2.67040 correct: 0.25531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   135] loss: 2.45390 correct: 0.29781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   148] loss: 2.28718 correct: 0.33641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = deque(maxlen=100), deque(maxlen=100)\n",
    "\n",
    "steps = 0\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    for i, data, verbose in enumerate_report(trainloader, 5):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = outputs.cpu().detach().argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(labels.cpu().view_as(pred)).sum().item()\n",
    "        accuracy = correct / float(len(labels))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "        steps += len(inputs)\n",
    "\n",
    "        if verbose and len(losses) > 5:\n",
    "            print(\n",
    "                \"[%d, %5d] loss: %.5f correct: %.5f\"\n",
    "                % (epoch + 1, i + 1, np.mean(losses), np.mean(accuracies))\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if steps > max_steps:\n",
    "            break\n",
    "\n",
    "    if steps > max_steps:\n",
    "        break\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 70.412954,
   "end_time": "2023-12-17T04:04:35.102376",
   "environment_variables": {},
   "exception": null,
   "input_path": "train-resnet50-wds.ipynb",
   "output_path": "out/_train-resnet50-wds.ipynb",
   "parameters": {
    "max_steps": 10000
   },
   "start_time": "2023-12-17T04:03:24.689422",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}