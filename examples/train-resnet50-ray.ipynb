{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-11 19:02:25,300\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import datasets, transforms\n",
    "import ray\n",
    "import webdataset as wds\n",
    "import dataclasses\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "def enumerate_report(seq, delta, growth=1.0):\n",
    "    last = 0\n",
    "    count = 0\n",
    "    for count, item in enumerate(seq):\n",
    "        now = time.time()\n",
    "        if now - last > delta:\n",
    "            last = now\n",
    "            yield count, item, True\n",
    "        else:\n",
    "            yield count, item, False\n",
    "        delta *= growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not running in colab, caching data locally in ./_cache\n",
      "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "bucket = \"https://storage.googleapis.com/webdataset/fake-imagenet\"\n",
    "trainset_url = bucket+\"/imagenet-train-{000000..001281}.tar\"\n",
    "valset_url = bucket+\"/imagenet-val-{000000..000049}.tar\"\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    cache_dir = None\n",
    "    print(\"running on colab, streaming data directly from storage\")\n",
    "else:\n",
    "    cache_dir = \"./_cache\"\n",
    "    print(f\"not running in colab, caching data locally in {cache_dir}\")\n",
    "\n",
    "def make_dataloader_train():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    def make_sample(sample):\n",
    "        return transform(sample[\"jpg\"]), sample[\"cls\"]\n",
    "    trainset = wds.WebDataset(trainset_url, resampled=True, cache_dir=cache_dir)\n",
    "    trainset = trainset.shuffle(1000).decode(\"pil\").map(make_sample)\n",
    "    trainset = trainset.batched(64)\n",
    "    trainloader = wds.WebLoader(trainset, batch_size=None, num_workers=4)\n",
    "    trainloader = trainloader.unbatched().batched(64).with_epoch(1282 * 100 // 64)\n",
    "    return trainloader\n",
    "\n",
    "def make_dataloader(split=\"train\"):\n",
    "    return getattr(sys.modules[__name__], f\"make_dataloader_{split}\")()\n",
    "\n",
    "sample = next(iter(make_dataloader()))\n",
    "print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Args:\n",
    "    epochs: int = 1\n",
    "    maxsteps: int = int(1e18)\n",
    "    lr: float = 0.001\n",
    "    momentum: float = 0.9\n",
    "    rank: int = 0\n",
    "    world_size: int = 2\n",
    "    backend: str = \"nccl\"\n",
    "    master_addr: str = \"localhost\"\n",
    "    master_port: str = \"12355\"\n",
    "    report_s: float = 15.0\n",
    "    report_growth: float = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rank, args):\n",
    "    # Set up distributed PyTorch.\n",
    "    if rank is not None:\n",
    "        os.environ['MASTER_ADDR'] = args.master_addr\n",
    "        os.environ['MASTER_PORT'] = args.master_port\n",
    "        dist.init_process_group(backend=args.backend, rank=rank, world_size=args.world_size)\n",
    "\n",
    "    # Define the model, loss function, and optimizer\n",
    "    model = resnet50(pretrained=False).cuda()\n",
    "    if rank is not None:\n",
    "        model = DistributedDataParallel(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Data loading code\n",
    "    trainloader = make_dataloader(split='train')\n",
    "\n",
    "    losses, accuracies, steps = deque(maxlen=100), deque(maxlen=100), 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(args.epochs):\n",
    "        for i, data, verbose in enumerate_report(trainloader, args.report_s):\n",
    "            inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # update statistics\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            accuracy = (outputs.argmax(1) == labels).float().mean()  # calculate accuracy\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(accuracy.item())\n",
    "\n",
    "            if verbose and len(losses) > 0:\n",
    "                avgloss = sum(losses)/len(losses)\n",
    "                avgaccuracy = sum(accuracies)/len(accuracies)\n",
    "                print(f\"rank {rank} epoch {epoch:5d}/{i:9d} loss {avgloss:8.3f} acc {avgaccuracy:8.3f} {steps:9d}\", file=sys.stderr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            steps += len(labels)\n",
    "            if steps > args.maxsteps:\n",
    "                print(\"finished training (maxsteps)\", steps, args.maxsteps, file=sys.stderr)\n",
    "                return\n",
    "\n",
    "    print(\"finished Training\", steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "rank None epoch     0/        0 loss    6.939 acc    0.000         0\n",
      "rank None epoch     0/       94 loss    4.281 acc    0.070      6016\n",
      "rank None epoch     0/      189 loss    3.021 acc    0.104     12096\n",
      "rank None epoch     0/      284 loss    2.898 acc    0.103     18176\n",
      "rank None epoch     0/      379 loss    2.862 acc    0.096     24256\n",
      "rank None epoch     0/      475 loss    2.803 acc    0.110     30400\n",
      "rank None epoch     0/      570 loss    2.758 acc    0.133     36480\n",
      "rank None epoch     0/      665 loss    2.727 acc    0.132     42560\n",
      "rank None epoch     0/      759 loss    2.693 acc    0.156     48576\n",
      "rank None epoch     0/      854 loss    2.694 acc    0.154     54656\n",
      "rank None epoch     0/      950 loss    2.702 acc    0.159     60800\n",
      "rank None epoch     0/     1046 loss    2.664 acc    0.179     66944\n",
      "rank None epoch     0/     1141 loss    2.627 acc    0.194     73024\n",
      "rank None epoch     0/     1236 loss    2.597 acc    0.199     79104\n",
      "rank None epoch     0/     1330 loss    2.581 acc    0.197     85120\n",
      "rank None epoch     0/     1425 loss    2.549 acc    0.220     91200\n",
      "rank None epoch     0/     1520 loss    2.546 acc    0.232     97280\n",
      "finished training (maxsteps) 100032 100000\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "args.epochs = 1\n",
    "args.maxsteps = 100000\n",
    "train(None, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@ray.remote(num_gpus=1)\n",
    "def train_remote(args):\n",
    "    # Ray will automatically set CUDA_VISIBLE_DEVICES for each task.\n",
    "    train(0, args)\n",
    "\n",
    "def distributed_training(world_size=2):\n",
    "    ray.init()\n",
    "    args = Args()\n",
    "    num_gpus = ray.available_resources()['GPU']\n",
    "    args.world_size = min(world_size, num_gpus)\n",
    "    results = ray.get([train_remote.remote(args) for _ in range(args.world_size)])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
