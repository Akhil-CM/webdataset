{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b555e25-e3a4-470d-95c5-26f47ceef051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f37a6f-a945-4581-8c8c-e2276b2a9c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    target = f\"imagenet-{i:06d}.tgz\"\n",
    "    if os.path.islink(target):\n",
    "        continue\n",
    "    os.symlink(\"../testdata/imagenet-000000.tgz\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1982b90b-8e75-4205-90c6-97cd44e37c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile demo.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import webdataset as wds\n",
    "from functools import partial\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "def mockdata(_):\n",
    "    return torch.randn(10), torch.randn(5)\n",
    "\n",
    "os.environ[\"GOPEN_VERBOSE\"] = \"1\"\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "    \n",
    "def make_loader():\n",
    "    shardlist = partial(wds.PytorchShardList, epoch_shuffle=True, verbose=False)\n",
    "    dataset = wds.WebDataset(\"imagenet-{000000..000015}.tgz\", shardlist=shardlist).map(mockdata)\n",
    "    loader = wds.WebLoader(dataset, num_workers=4, batch_size=20)\n",
    "    return loader\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "    \n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "def demo_basic(rank, world_size):\n",
    "    print(f\"Running basic DDP example on rank {rank} of {world_size}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # create model and move it to GPU with id rank\n",
    "    model = ToyModel().to(rank)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    loader = make_loader()\n",
    "    for epoch in range(2):\n",
    "        print(\"=== epoch\", epoch)\n",
    "        os.environ[\"WDS_EPOCH\"] = str(epoch)\n",
    "        for inputs, labels in loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = ddp_model(inputs.to(rank))\n",
    "            loss_fn(outputs, labels.to(rank)).backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa8c7b8-8aca-4d7e-9f3d-514c4e460fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'demo' from '/home1/tmb/proj/webdataset/notebooks/demo.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imp import reload\n",
    "import demo\n",
    "reload(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48815cae-56a4-45b0-850d-fa5c0413772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "def run_demo(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,),\n",
    "             nprocs=world_size,\n",
    "             join=True)\n",
    "    \n",
    "run_demo(demo.demo_basic, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485467a-2414-42ad-98a5-dcfb3cdf50fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001e4cf-20c9-4fc8-a339-20c4052df5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
